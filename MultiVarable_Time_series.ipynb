{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import os as os\n",
    "import pandas as pandas\n",
    "import pickle as pickle\n",
    "import pyspark as pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def poloUrl(pair, start, end, period):\n",
    "    return 'https://poloniex.com/public?command=returnChartData&currencyPair={}&start={}&end={}&period={}'.format(pair, start.timestamp(), end.timestamp(), period)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairUrl(pair):\n",
    "    start = datetime.strptime('2015-01-01', '%Y-%m-%d')\n",
    "    end = datetime.now()\n",
    "    period = 86400\n",
    "    return poloUrl(pair, start, end, period)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cachedPath(pair):\n",
    "    return pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cachedPair(pair):\n",
    "    path = cachedPath(pair)\n",
    "    if os.path.exists(path): \n",
    "        print('Load From Cache: {}'.format(path))\n",
    "        file = open(path, 'rb')\n",
    "        data = pickle.load(file)\n",
    "        return data\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downloadPair(pair):\n",
    "    url = pairUrl(pair)\n",
    "    print('Downloading {}'.format(url))\n",
    "    data = pandas.read_json(url)\n",
    "    return data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPair(pair):\n",
    "    data = cachedPair(pair)\n",
    "    # data = None\n",
    "    if data is None:\n",
    "        data = downloadPair(pair)\n",
    "        data.to_pickle(cachedPath(pair))\n",
    "    return data.set_index('date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calRaised(data):\n",
    "    data['raised'] = data['close'] > data['open']\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seriesToSupervised(data, nIn, nOut, dropnan = True):\n",
    "    nVars = data.shape[1]\n",
    "    cols, names = list(), list()\n",
    "    for i in range(nIn, 0, -1):\n",
    "        cols.append(data.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(nVars)]\n",
    "    for i in range(0, nOut):\n",
    "        cols.append(data.shift(-i))\n",
    "        if i == 0:\n",
    "            names += [('var%d(t)' % (j+1)) for j in range(nVars)]\n",
    "        else:\n",
    "            names += [('var%d(t+%d)' % (j+1, i)) for j in range(nVars)]\n",
    "    agg = pandas.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "        agg.dropna(inplace=True)\n",
    "    agg.drop( [('var%d(t)' % (j+1)) for j in range(1, nVars)], axis=1)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load From Cache: USDT_ETH\n",
      "(365, 1, 487) (365,) (96, 1, 487) (96,)\n"
     ]
    }
   ],
   "source": [
    "data = seriesToSupervised(calRaised(getPair('USDT_ETH')), 60, 1, True)\n",
    "\n",
    "\n",
    "\n",
    "train = data.loc[\"2016-10-01\":\"2017-9-30\"].values\n",
    "test = data.loc[\"2017-10-01\":].values\n",
    "\n",
    "trainX, trainY = train[:, :-1], train[:, -1]\n",
    "testX, testY = test[:, :-1], test[:, -1]\n",
    "\n",
    "#print(trainX.shape, trainY.shape, testX.shape, testY.shape)\n",
    "\n",
    "trainX = trainX.reshape((trainX.shape[0], 1, trainX.shape[1]))\n",
    "testX = testX.reshape((testX.shape[0], 1, testX.shape[1]))\n",
    "\n",
    "print(trainX.shape, trainY.shape, testX.shape, testY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 365 samples, validate on 96 samples\n",
      "Epoch 1/300\n",
      "365/365 [==============================] - 2s 6ms/step - loss: 0.5237 - acc: 0.4849 - val_loss: 0.5311 - val_acc: 0.4375\n",
      "Epoch 2/300\n",
      "365/365 [==============================] - 0s 506us/step - loss: 0.4934 - acc: 0.4849 - val_loss: 0.5116 - val_acc: 0.4375\n",
      "Epoch 3/300\n",
      "365/365 [==============================] - 0s 558us/step - loss: 0.4927 - acc: 0.4986 - val_loss: 0.4975 - val_acc: 0.5208\n",
      "Epoch 4/300\n",
      "365/365 [==============================] - 0s 599us/step - loss: 0.4714 - acc: 0.5233 - val_loss: 0.4846 - val_acc: 0.5625\n",
      "Epoch 5/300\n",
      "365/365 [==============================] - 0s 635us/step - loss: 0.4618 - acc: 0.5562 - val_loss: 0.4723 - val_acc: 0.5417\n",
      "Epoch 6/300\n",
      "365/365 [==============================] - 0s 522us/step - loss: 0.4410 - acc: 0.6247 - val_loss: 0.4589 - val_acc: 0.5625\n",
      "Epoch 7/300\n",
      "365/365 [==============================] - 0s 584us/step - loss: 0.4236 - acc: 0.6603 - val_loss: 0.4475 - val_acc: 0.5521\n",
      "Epoch 8/300\n",
      "365/365 [==============================] - 0s 512us/step - loss: 0.4151 - acc: 0.6630 - val_loss: 0.4437 - val_acc: 0.5521\n",
      "Epoch 9/300\n",
      "365/365 [==============================] - 0s 604us/step - loss: 0.3942 - acc: 0.7014 - val_loss: 0.4449 - val_acc: 0.5521\n",
      "Epoch 10/300\n",
      "365/365 [==============================] - 0s 616us/step - loss: 0.3874 - acc: 0.6932 - val_loss: 0.4489 - val_acc: 0.5521\n",
      "Epoch 11/300\n",
      "365/365 [==============================] - 0s 539us/step - loss: 0.3911 - acc: 0.6904 - val_loss: 0.4530 - val_acc: 0.5417\n",
      "Epoch 12/300\n",
      "365/365 [==============================] - 0s 616us/step - loss: 0.3907 - acc: 0.6630 - val_loss: 0.4537 - val_acc: 0.5417\n",
      "Epoch 13/300\n",
      "365/365 [==============================] - 0s 778us/step - loss: 0.3872 - acc: 0.6685 - val_loss: 0.4527 - val_acc: 0.5313\n",
      "Epoch 14/300\n",
      "365/365 [==============================] - 0s 608us/step - loss: 0.3841 - acc: 0.6932 - val_loss: 0.4514 - val_acc: 0.5521\n",
      "Epoch 15/300\n",
      "365/365 [==============================] - 0s 718us/step - loss: 0.3594 - acc: 0.7425 - val_loss: 0.4509 - val_acc: 0.5625\n",
      "Epoch 16/300\n",
      "365/365 [==============================] - 0s 605us/step - loss: 0.3726 - acc: 0.7068 - val_loss: 0.4505 - val_acc: 0.5625\n",
      "Epoch 17/300\n",
      "365/365 [==============================] - 0s 528us/step - loss: 0.3498 - acc: 0.7260 - val_loss: 0.4496 - val_acc: 0.5625\n",
      "Epoch 18/300\n",
      "365/365 [==============================] - 0s 529us/step - loss: 0.3637 - acc: 0.6986 - val_loss: 0.4490 - val_acc: 0.5625\n",
      "Epoch 19/300\n",
      "365/365 [==============================] - 0s 542us/step - loss: 0.3599 - acc: 0.7288 - val_loss: 0.4467 - val_acc: 0.5625\n",
      "Epoch 20/300\n",
      "365/365 [==============================] - 0s 540us/step - loss: 0.3598 - acc: 0.7452 - val_loss: 0.4435 - val_acc: 0.5833\n",
      "Epoch 21/300\n",
      "365/365 [==============================] - 0s 558us/step - loss: 0.3592 - acc: 0.7342 - val_loss: 0.4434 - val_acc: 0.5729\n",
      "Epoch 22/300\n",
      "365/365 [==============================] - 0s 598us/step - loss: 0.3371 - acc: 0.7644 - val_loss: 0.4453 - val_acc: 0.5625\n",
      "Epoch 23/300\n",
      "365/365 [==============================] - 0s 516us/step - loss: 0.3407 - acc: 0.7562 - val_loss: 0.4488 - val_acc: 0.5625\n",
      "Epoch 24/300\n",
      "365/365 [==============================] - 0s 559us/step - loss: 0.3472 - acc: 0.7562 - val_loss: 0.4485 - val_acc: 0.5521\n",
      "Epoch 25/300\n",
      "365/365 [==============================] - 0s 532us/step - loss: 0.3352 - acc: 0.7534 - val_loss: 0.4437 - val_acc: 0.5625\n",
      "Epoch 26/300\n",
      "365/365 [==============================] - 0s 544us/step - loss: 0.3460 - acc: 0.7260 - val_loss: 0.4426 - val_acc: 0.5625\n",
      "Epoch 27/300\n",
      "365/365 [==============================] - 0s 559us/step - loss: 0.3445 - acc: 0.7616 - val_loss: 0.4403 - val_acc: 0.5625\n",
      "Epoch 28/300\n",
      "365/365 [==============================] - 0s 563us/step - loss: 0.3330 - acc: 0.7863 - val_loss: 0.4417 - val_acc: 0.5625\n",
      "Epoch 29/300\n",
      "365/365 [==============================] - 0s 515us/step - loss: 0.3251 - acc: 0.7863 - val_loss: 0.4433 - val_acc: 0.5833\n",
      "Epoch 30/300\n",
      "365/365 [==============================] - 0s 553us/step - loss: 0.3278 - acc: 0.7699 - val_loss: 0.4416 - val_acc: 0.5729\n",
      "Epoch 31/300\n",
      "365/365 [==============================] - 0s 507us/step - loss: 0.3324 - acc: 0.7918 - val_loss: 0.4421 - val_acc: 0.5729\n",
      "Epoch 32/300\n",
      "365/365 [==============================] - 0s 516us/step - loss: 0.3202 - acc: 0.7808 - val_loss: 0.4465 - val_acc: 0.5521\n",
      "Epoch 33/300\n",
      "365/365 [==============================] - 0s 559us/step - loss: 0.3084 - acc: 0.8055 - val_loss: 0.4466 - val_acc: 0.5625\n",
      "Epoch 34/300\n",
      "365/365 [==============================] - 0s 566us/step - loss: 0.3069 - acc: 0.8082 - val_loss: 0.4447 - val_acc: 0.5833\n",
      "Epoch 35/300\n",
      "365/365 [==============================] - 0s 502us/step - loss: 0.3148 - acc: 0.8000 - val_loss: 0.4452 - val_acc: 0.5833\n",
      "Epoch 36/300\n",
      "365/365 [==============================] - 0s 595us/step - loss: 0.3083 - acc: 0.8000 - val_loss: 0.4460 - val_acc: 0.5833\n",
      "Epoch 37/300\n",
      "365/365 [==============================] - 0s 508us/step - loss: 0.2951 - acc: 0.8356 - val_loss: 0.4413 - val_acc: 0.5729\n",
      "Epoch 38/300\n",
      "365/365 [==============================] - 0s 544us/step - loss: 0.3031 - acc: 0.8164 - val_loss: 0.4416 - val_acc: 0.5729\n",
      "Epoch 39/300\n",
      "365/365 [==============================] - 0s 555us/step - loss: 0.2936 - acc: 0.8192 - val_loss: 0.4437 - val_acc: 0.5729\n",
      "Epoch 40/300\n",
      "365/365 [==============================] - 0s 539us/step - loss: 0.2971 - acc: 0.8219 - val_loss: 0.4485 - val_acc: 0.5833\n",
      "Epoch 41/300\n",
      "365/365 [==============================] - 0s 506us/step - loss: 0.2974 - acc: 0.8027 - val_loss: 0.4501 - val_acc: 0.5521\n",
      "Epoch 42/300\n",
      "365/365 [==============================] - 0s 548us/step - loss: 0.3017 - acc: 0.8466 - val_loss: 0.4527 - val_acc: 0.5521\n",
      "Epoch 43/300\n",
      "365/365 [==============================] - 0s 605us/step - loss: 0.2790 - acc: 0.8740 - val_loss: 0.4525 - val_acc: 0.5625\n",
      "Epoch 44/300\n",
      "365/365 [==============================] - 0s 681us/step - loss: 0.2789 - acc: 0.8575 - val_loss: 0.4504 - val_acc: 0.5625\n",
      "Epoch 45/300\n",
      "365/365 [==============================] - 0s 537us/step - loss: 0.2833 - acc: 0.8493 - val_loss: 0.4483 - val_acc: 0.5938\n",
      "Epoch 46/300\n",
      "365/365 [==============================] - 0s 721us/step - loss: 0.2716 - acc: 0.8740 - val_loss: 0.4462 - val_acc: 0.5729\n",
      "Epoch 47/300\n",
      "365/365 [==============================] - 0s 609us/step - loss: 0.2849 - acc: 0.8438 - val_loss: 0.4412 - val_acc: 0.5729\n",
      "Epoch 48/300\n",
      "365/365 [==============================] - 0s 887us/step - loss: 0.2629 - acc: 0.8630 - val_loss: 0.4448 - val_acc: 0.5729\n",
      "Epoch 49/300\n",
      "365/365 [==============================] - 0s 573us/step - loss: 0.2726 - acc: 0.8658 - val_loss: 0.4394 - val_acc: 0.5833\n",
      "Epoch 50/300\n",
      "365/365 [==============================] - 0s 661us/step - loss: 0.2689 - acc: 0.8521 - val_loss: 0.4339 - val_acc: 0.5938\n",
      "Epoch 51/300\n",
      "365/365 [==============================] - 0s 669us/step - loss: 0.2727 - acc: 0.8712 - val_loss: 0.4352 - val_acc: 0.5625\n",
      "Epoch 52/300\n",
      "365/365 [==============================] - 0s 639us/step - loss: 0.2717 - acc: 0.8712 - val_loss: 0.4352 - val_acc: 0.5729\n",
      "Epoch 53/300\n",
      "365/365 [==============================] - 0s 730us/step - loss: 0.2541 - acc: 0.8767 - val_loss: 0.4335 - val_acc: 0.5729\n",
      "Epoch 54/300\n",
      "365/365 [==============================] - 0s 528us/step - loss: 0.2528 - acc: 0.8959 - val_loss: 0.4358 - val_acc: 0.6042\n",
      "Epoch 55/300\n",
      "365/365 [==============================] - 0s 758us/step - loss: 0.2485 - acc: 0.8877 - val_loss: 0.4319 - val_acc: 0.6042\n",
      "Epoch 56/300\n",
      "365/365 [==============================] - 0s 572us/step - loss: 0.2506 - acc: 0.8822 - val_loss: 0.4313 - val_acc: 0.6042\n",
      "Epoch 57/300\n",
      "365/365 [==============================] - 0s 555us/step - loss: 0.2320 - acc: 0.9041 - val_loss: 0.4369 - val_acc: 0.5833\n",
      "Epoch 58/300\n",
      "365/365 [==============================] - 0s 759us/step - loss: 0.2534 - acc: 0.9041 - val_loss: 0.4420 - val_acc: 0.5625\n",
      "Epoch 59/300\n",
      "365/365 [==============================] - 0s 743us/step - loss: 0.2378 - acc: 0.9041 - val_loss: 0.4373 - val_acc: 0.5938\n",
      "Epoch 60/300\n",
      "365/365 [==============================] - 0s 698us/step - loss: 0.2550 - acc: 0.9123 - val_loss: 0.4387 - val_acc: 0.5938\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/300\n",
      "365/365 [==============================] - 0s 738us/step - loss: 0.2405 - acc: 0.8904 - val_loss: 0.4392 - val_acc: 0.5521\n",
      "Epoch 62/300\n",
      "365/365 [==============================] - 0s 678us/step - loss: 0.2217 - acc: 0.9260 - val_loss: 0.4285 - val_acc: 0.6146\n",
      "Epoch 63/300\n",
      "365/365 [==============================] - 0s 685us/step - loss: 0.2275 - acc: 0.9068 - val_loss: 0.4300 - val_acc: 0.5833\n",
      "Epoch 64/300\n",
      "365/365 [==============================] - 0s 590us/step - loss: 0.2197 - acc: 0.9233 - val_loss: 0.4330 - val_acc: 0.5625\n",
      "Epoch 65/300\n",
      "365/365 [==============================] - 0s 536us/step - loss: 0.2207 - acc: 0.9288 - val_loss: 0.4341 - val_acc: 0.5625\n",
      "Epoch 66/300\n",
      "365/365 [==============================] - 0s 879us/step - loss: 0.2307 - acc: 0.9342 - val_loss: 0.4353 - val_acc: 0.5417\n",
      "Epoch 67/300\n",
      "365/365 [==============================] - 0s 785us/step - loss: 0.2164 - acc: 0.9288 - val_loss: 0.4321 - val_acc: 0.5625\n",
      "Epoch 68/300\n",
      "365/365 [==============================] - 0s 542us/step - loss: 0.2242 - acc: 0.9233 - val_loss: 0.4303 - val_acc: 0.5521\n",
      "Epoch 69/300\n",
      "365/365 [==============================] - 0s 640us/step - loss: 0.2058 - acc: 0.9370 - val_loss: 0.4330 - val_acc: 0.5521\n",
      "Epoch 70/300\n",
      "365/365 [==============================] - 0s 637us/step - loss: 0.2141 - acc: 0.9589 - val_loss: 0.4321 - val_acc: 0.5729\n",
      "Epoch 71/300\n",
      "365/365 [==============================] - 0s 881us/step - loss: 0.2101 - acc: 0.9370 - val_loss: 0.4364 - val_acc: 0.5729\n",
      "Epoch 72/300\n",
      "365/365 [==============================] - 0s 762us/step - loss: 0.2091 - acc: 0.9288 - val_loss: 0.4434 - val_acc: 0.5521\n",
      "Epoch 73/300\n",
      "365/365 [==============================] - 0s 631us/step - loss: 0.2127 - acc: 0.9260 - val_loss: 0.4408 - val_acc: 0.5833\n",
      "Epoch 74/300\n",
      "365/365 [==============================] - 0s 636us/step - loss: 0.2068 - acc: 0.9507 - val_loss: 0.4420 - val_acc: 0.5833\n",
      "Epoch 75/300\n",
      "365/365 [==============================] - 0s 563us/step - loss: 0.2072 - acc: 0.9562 - val_loss: 0.4501 - val_acc: 0.5625\n",
      "Epoch 76/300\n",
      "365/365 [==============================] - 0s 608us/step - loss: 0.2109 - acc: 0.9507 - val_loss: 0.4554 - val_acc: 0.5312\n",
      "Epoch 77/300\n",
      "365/365 [==============================] - 0s 798us/step - loss: 0.1933 - acc: 0.9671 - val_loss: 0.4462 - val_acc: 0.5938\n",
      "Epoch 78/300\n",
      "365/365 [==============================] - 0s 1ms/step - loss: 0.1897 - acc: 0.9534 - val_loss: 0.4392 - val_acc: 0.6250\n",
      "Epoch 79/300\n",
      "365/365 [==============================] - 0s 721us/step - loss: 0.1919 - acc: 0.9589 - val_loss: 0.4440 - val_acc: 0.5833\n",
      "Epoch 80/300\n",
      "365/365 [==============================] - 0s 716us/step - loss: 0.1845 - acc: 0.9562 - val_loss: 0.4439 - val_acc: 0.5729\n",
      "Epoch 81/300\n",
      "365/365 [==============================] - 0s 819us/step - loss: 0.1859 - acc: 0.9699 - val_loss: 0.4320 - val_acc: 0.6042\n",
      "Epoch 82/300\n",
      "365/365 [==============================] - 0s 596us/step - loss: 0.2020 - acc: 0.9507 - val_loss: 0.4359 - val_acc: 0.5938\n",
      "Epoch 83/300\n",
      "365/365 [==============================] - 0s 937us/step - loss: 0.1828 - acc: 0.9781 - val_loss: 0.4365 - val_acc: 0.5833\n",
      "Epoch 84/300\n",
      "365/365 [==============================] - 0s 546us/step - loss: 0.1850 - acc: 0.9644 - val_loss: 0.4343 - val_acc: 0.5625\n",
      "Epoch 85/300\n",
      "365/365 [==============================] - 0s 632us/step - loss: 0.1922 - acc: 0.9507 - val_loss: 0.4431 - val_acc: 0.5833\n",
      "Epoch 86/300\n",
      "365/365 [==============================] - 0s 611us/step - loss: 0.1877 - acc: 0.9507 - val_loss: 0.4397 - val_acc: 0.5729\n",
      "Epoch 87/300\n",
      "365/365 [==============================] - 0s 877us/step - loss: 0.1829 - acc: 0.9726 - val_loss: 0.4383 - val_acc: 0.5521\n",
      "Epoch 88/300\n",
      "365/365 [==============================] - 0s 866us/step - loss: 0.1924 - acc: 0.9562 - val_loss: 0.4331 - val_acc: 0.5729\n",
      "Epoch 89/300\n",
      "365/365 [==============================] - 0s 513us/step - loss: 0.1766 - acc: 0.9671 - val_loss: 0.4345 - val_acc: 0.5833\n",
      "Epoch 90/300\n",
      "365/365 [==============================] - 0s 550us/step - loss: 0.1865 - acc: 0.9699 - val_loss: 0.4383 - val_acc: 0.5833\n",
      "Epoch 91/300\n",
      "365/365 [==============================] - 0s 661us/step - loss: 0.1850 - acc: 0.9699 - val_loss: 0.4361 - val_acc: 0.5938\n",
      "Epoch 92/300\n",
      "365/365 [==============================] - 0s 506us/step - loss: 0.1656 - acc: 0.9836 - val_loss: 0.4331 - val_acc: 0.5938\n",
      "Epoch 93/300\n",
      "365/365 [==============================] - 0s 499us/step - loss: 0.1761 - acc: 0.9726 - val_loss: 0.4354 - val_acc: 0.6354\n",
      "Epoch 94/300\n",
      "365/365 [==============================] - 0s 530us/step - loss: 0.1779 - acc: 0.9753 - val_loss: 0.4316 - val_acc: 0.6562\n",
      "Epoch 95/300\n",
      "365/365 [==============================] - 0s 550us/step - loss: 0.1712 - acc: 0.9699 - val_loss: 0.4233 - val_acc: 0.6146\n",
      "Epoch 96/300\n",
      "365/365 [==============================] - 0s 535us/step - loss: 0.1824 - acc: 0.9671 - val_loss: 0.4382 - val_acc: 0.6354\n",
      "Epoch 97/300\n",
      "365/365 [==============================] - 0s 497us/step - loss: 0.1805 - acc: 0.9808 - val_loss: 0.4362 - val_acc: 0.5938\n",
      "Epoch 98/300\n",
      "365/365 [==============================] - 0s 519us/step - loss: 0.1784 - acc: 0.9726 - val_loss: 0.4376 - val_acc: 0.5938\n",
      "Epoch 99/300\n",
      "365/365 [==============================] - 0s 718us/step - loss: 0.1703 - acc: 0.9726 - val_loss: 0.4418 - val_acc: 0.5938\n",
      "Epoch 100/300\n",
      "365/365 [==============================] - 0s 517us/step - loss: 0.1915 - acc: 0.9753 - val_loss: 0.4469 - val_acc: 0.5729\n",
      "Epoch 101/300\n",
      "365/365 [==============================] - 0s 526us/step - loss: 0.1797 - acc: 0.9781 - val_loss: 0.4506 - val_acc: 0.5833\n",
      "Epoch 102/300\n",
      "365/365 [==============================] - 0s 516us/step - loss: 0.1763 - acc: 0.9753 - val_loss: 0.4406 - val_acc: 0.5938\n",
      "Epoch 103/300\n",
      "365/365 [==============================] - 0s 525us/step - loss: 0.1791 - acc: 0.9808 - val_loss: 0.4361 - val_acc: 0.5938\n",
      "Epoch 104/300\n",
      "365/365 [==============================] - 0s 524us/step - loss: 0.1719 - acc: 0.9808 - val_loss: 0.4349 - val_acc: 0.5938\n",
      "Epoch 105/300\n",
      "365/365 [==============================] - 0s 509us/step - loss: 0.1713 - acc: 0.9890 - val_loss: 0.4337 - val_acc: 0.6042\n",
      "Epoch 106/300\n",
      "365/365 [==============================] - 0s 530us/step - loss: 0.1804 - acc: 0.9753 - val_loss: 0.4261 - val_acc: 0.5729\n",
      "Epoch 107/300\n",
      "365/365 [==============================] - 0s 503us/step - loss: 0.1696 - acc: 0.9753 - val_loss: 0.4251 - val_acc: 0.5938\n",
      "Epoch 108/300\n",
      "365/365 [==============================] - 0s 484us/step - loss: 0.1683 - acc: 0.9890 - val_loss: 0.4341 - val_acc: 0.5938\n",
      "Epoch 109/300\n",
      "365/365 [==============================] - 0s 499us/step - loss: 0.1730 - acc: 0.9945 - val_loss: 0.4395 - val_acc: 0.5833\n",
      "Epoch 110/300\n",
      "365/365 [==============================] - 0s 574us/step - loss: 0.1716 - acc: 0.9699 - val_loss: 0.4399 - val_acc: 0.6042\n",
      "Epoch 111/300\n",
      "365/365 [==============================] - 0s 497us/step - loss: 0.1618 - acc: 0.9699 - val_loss: 0.4347 - val_acc: 0.5938\n",
      "Epoch 112/300\n",
      "365/365 [==============================] - 0s 550us/step - loss: 0.1754 - acc: 0.9753 - val_loss: 0.4376 - val_acc: 0.6042\n",
      "Epoch 113/300\n",
      "365/365 [==============================] - 0s 481us/step - loss: 0.1638 - acc: 0.9890 - val_loss: 0.4390 - val_acc: 0.6250\n",
      "Epoch 114/300\n",
      "365/365 [==============================] - 0s 520us/step - loss: 0.1708 - acc: 0.9781 - val_loss: 0.4309 - val_acc: 0.5729\n",
      "Epoch 115/300\n",
      "365/365 [==============================] - 0s 535us/step - loss: 0.1680 - acc: 0.9808 - val_loss: 0.4321 - val_acc: 0.6146\n",
      "Epoch 116/300\n",
      "365/365 [==============================] - 0s 610us/step - loss: 0.1651 - acc: 0.9753 - val_loss: 0.4282 - val_acc: 0.6042\n",
      "Epoch 117/300\n",
      "365/365 [==============================] - 0s 513us/step - loss: 0.1522 - acc: 0.9945 - val_loss: 0.4293 - val_acc: 0.5729\n",
      "Epoch 118/300\n",
      "365/365 [==============================] - 0s 526us/step - loss: 0.1643 - acc: 0.9863 - val_loss: 0.4329 - val_acc: 0.5729\n",
      "Epoch 119/300\n",
      "365/365 [==============================] - 0s 503us/step - loss: 0.1682 - acc: 0.9890 - val_loss: 0.4289 - val_acc: 0.5833\n",
      "Epoch 120/300\n",
      "365/365 [==============================] - 0s 497us/step - loss: 0.1720 - acc: 0.9890 - val_loss: 0.4309 - val_acc: 0.6042\n",
      "Epoch 121/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "365/365 [==============================] - 0s 542us/step - loss: 0.1600 - acc: 0.9863 - val_loss: 0.4344 - val_acc: 0.5938\n",
      "Epoch 122/300\n",
      "365/365 [==============================] - 0s 533us/step - loss: 0.1696 - acc: 0.9863 - val_loss: 0.4264 - val_acc: 0.6250\n",
      "Epoch 123/300\n",
      "365/365 [==============================] - 0s 543us/step - loss: 0.1575 - acc: 0.9890 - val_loss: 0.4301 - val_acc: 0.6146\n",
      "Epoch 124/300\n",
      "365/365 [==============================] - 0s 526us/step - loss: 0.1518 - acc: 0.9836 - val_loss: 0.4330 - val_acc: 0.6250\n",
      "Epoch 125/300\n",
      "365/365 [==============================] - 0s 519us/step - loss: 0.1599 - acc: 0.9890 - val_loss: 0.4301 - val_acc: 0.6250\n",
      "Epoch 126/300\n",
      "365/365 [==============================] - 0s 527us/step - loss: 0.1609 - acc: 0.9836 - val_loss: 0.4316 - val_acc: 0.6354\n",
      "Epoch 127/300\n",
      "365/365 [==============================] - 0s 548us/step - loss: 0.1651 - acc: 0.9726 - val_loss: 0.4315 - val_acc: 0.6354\n",
      "Epoch 128/300\n",
      "365/365 [==============================] - 0s 483us/step - loss: 0.1571 - acc: 0.9781 - val_loss: 0.4354 - val_acc: 0.6146\n",
      "Epoch 129/300\n",
      "365/365 [==============================] - 0s 515us/step - loss: 0.1565 - acc: 0.9836 - val_loss: 0.4331 - val_acc: 0.6250\n",
      "Epoch 130/300\n",
      "365/365 [==============================] - 0s 516us/step - loss: 0.1669 - acc: 0.9918 - val_loss: 0.4354 - val_acc: 0.6354\n",
      "Epoch 131/300\n",
      "365/365 [==============================] - 0s 540us/step - loss: 0.1587 - acc: 0.9863 - val_loss: 0.4291 - val_acc: 0.6146\n",
      "Epoch 132/300\n",
      "365/365 [==============================] - 0s 519us/step - loss: 0.1664 - acc: 0.9973 - val_loss: 0.4311 - val_acc: 0.6146\n",
      "Epoch 133/300\n",
      "365/365 [==============================] - 0s 515us/step - loss: 0.1570 - acc: 0.9945 - val_loss: 0.4277 - val_acc: 0.5833\n",
      "Epoch 134/300\n",
      "365/365 [==============================] - 0s 488us/step - loss: 0.1541 - acc: 0.9890 - val_loss: 0.4265 - val_acc: 0.6042\n",
      "Epoch 135/300\n",
      "365/365 [==============================] - 0s 478us/step - loss: 0.1637 - acc: 0.9808 - val_loss: 0.4412 - val_acc: 0.6042\n",
      "Epoch 136/300\n",
      "365/365 [==============================] - 0s 517us/step - loss: 0.1560 - acc: 0.9863 - val_loss: 0.4356 - val_acc: 0.5833\n",
      "Epoch 137/300\n",
      "365/365 [==============================] - 0s 500us/step - loss: 0.1536 - acc: 0.9890 - val_loss: 0.4339 - val_acc: 0.5833\n",
      "Epoch 138/300\n",
      "365/365 [==============================] - 0s 501us/step - loss: 0.1675 - acc: 0.9781 - val_loss: 0.4329 - val_acc: 0.6146\n",
      "Epoch 139/300\n",
      "365/365 [==============================] - 0s 498us/step - loss: 0.1570 - acc: 0.9973 - val_loss: 0.4322 - val_acc: 0.6146\n",
      "Epoch 140/300\n",
      "365/365 [==============================] - 0s 532us/step - loss: 0.1573 - acc: 0.9918 - val_loss: 0.4376 - val_acc: 0.6146\n",
      "Epoch 141/300\n",
      "365/365 [==============================] - 0s 512us/step - loss: 0.1607 - acc: 0.9808 - val_loss: 0.4391 - val_acc: 0.5938\n",
      "Epoch 142/300\n",
      "365/365 [==============================] - 0s 549us/step - loss: 0.1496 - acc: 0.9945 - val_loss: 0.4425 - val_acc: 0.5938\n",
      "Epoch 143/300\n",
      "365/365 [==============================] - 0s 541us/step - loss: 0.1604 - acc: 0.9808 - val_loss: 0.4467 - val_acc: 0.6042\n",
      "Epoch 144/300\n",
      "365/365 [==============================] - 0s 499us/step - loss: 0.1595 - acc: 0.9890 - val_loss: 0.4430 - val_acc: 0.5729\n",
      "Epoch 145/300\n",
      "365/365 [==============================] - 0s 501us/step - loss: 0.1553 - acc: 0.9863 - val_loss: 0.4358 - val_acc: 0.5833\n",
      "Epoch 146/300\n",
      "365/365 [==============================] - 0s 507us/step - loss: 0.1528 - acc: 0.9781 - val_loss: 0.4409 - val_acc: 0.6042\n",
      "Epoch 147/300\n",
      "365/365 [==============================] - 0s 540us/step - loss: 0.1634 - acc: 0.9808 - val_loss: 0.4394 - val_acc: 0.5833\n",
      "Epoch 148/300\n",
      "365/365 [==============================] - 0s 532us/step - loss: 0.1581 - acc: 1.0000 - val_loss: 0.4326 - val_acc: 0.5833\n",
      "Epoch 149/300\n",
      "365/365 [==============================] - 0s 562us/step - loss: 0.1552 - acc: 0.9918 - val_loss: 0.4306 - val_acc: 0.5833\n",
      "Epoch 150/300\n",
      "365/365 [==============================] - 0s 573us/step - loss: 0.1566 - acc: 0.9945 - val_loss: 0.4345 - val_acc: 0.5938\n",
      "Epoch 151/300\n",
      "365/365 [==============================] - 0s 512us/step - loss: 0.1564 - acc: 0.9890 - val_loss: 0.4323 - val_acc: 0.5938\n",
      "Epoch 152/300\n",
      "365/365 [==============================] - 0s 510us/step - loss: 0.1673 - acc: 0.9890 - val_loss: 0.4324 - val_acc: 0.5729\n",
      "Epoch 153/300\n",
      "365/365 [==============================] - 0s 503us/step - loss: 0.1444 - acc: 0.9918 - val_loss: 0.4353 - val_acc: 0.5625\n",
      "Epoch 154/300\n",
      "365/365 [==============================] - 0s 509us/step - loss: 0.1531 - acc: 0.9890 - val_loss: 0.4396 - val_acc: 0.6042\n",
      "Epoch 155/300\n",
      "365/365 [==============================] - 0s 509us/step - loss: 0.1595 - acc: 0.9973 - val_loss: 0.4410 - val_acc: 0.6146\n",
      "Epoch 156/300\n",
      "365/365 [==============================] - 0s 503us/step - loss: 0.1493 - acc: 0.9808 - val_loss: 0.4394 - val_acc: 0.6042\n",
      "Epoch 157/300\n",
      "365/365 [==============================] - 0s 508us/step - loss: 0.1594 - acc: 0.9890 - val_loss: 0.4439 - val_acc: 0.6042\n",
      "Epoch 158/300\n",
      "365/365 [==============================] - 0s 505us/step - loss: 0.1582 - acc: 0.9836 - val_loss: 0.4507 - val_acc: 0.5833\n",
      "Epoch 159/300\n",
      "365/365 [==============================] - 0s 550us/step - loss: 0.1452 - acc: 0.9863 - val_loss: 0.4544 - val_acc: 0.5833\n",
      "Epoch 160/300\n",
      "365/365 [==============================] - 0s 500us/step - loss: 0.1656 - acc: 0.9726 - val_loss: 0.4450 - val_acc: 0.5833\n",
      "Epoch 161/300\n",
      "365/365 [==============================] - 0s 540us/step - loss: 0.1583 - acc: 0.9918 - val_loss: 0.4433 - val_acc: 0.6146\n",
      "Epoch 162/300\n",
      "365/365 [==============================] - 0s 525us/step - loss: 0.1445 - acc: 0.9918 - val_loss: 0.4407 - val_acc: 0.5938\n",
      "Epoch 163/300\n",
      "365/365 [==============================] - 0s 517us/step - loss: 0.1555 - acc: 0.9890 - val_loss: 0.4352 - val_acc: 0.5833\n",
      "Epoch 164/300\n",
      "365/365 [==============================] - 0s 522us/step - loss: 0.1570 - acc: 0.9945 - val_loss: 0.4263 - val_acc: 0.5833\n",
      "Epoch 165/300\n",
      "365/365 [==============================] - 0s 538us/step - loss: 0.1624 - acc: 0.9863 - val_loss: 0.4285 - val_acc: 0.5833\n",
      "Epoch 166/300\n",
      "365/365 [==============================] - 0s 495us/step - loss: 0.1444 - acc: 0.9890 - val_loss: 0.4349 - val_acc: 0.6042\n",
      "Epoch 167/300\n",
      "365/365 [==============================] - 0s 488us/step - loss: 0.1479 - acc: 0.9918 - val_loss: 0.4404 - val_acc: 0.5833\n",
      "Epoch 168/300\n",
      "365/365 [==============================] - 0s 614us/step - loss: 0.1474 - acc: 0.9945 - val_loss: 0.4469 - val_acc: 0.5833\n",
      "Epoch 169/300\n",
      "365/365 [==============================] - 0s 506us/step - loss: 0.1485 - acc: 0.9918 - val_loss: 0.4509 - val_acc: 0.5729\n",
      "Epoch 170/300\n",
      "365/365 [==============================] - 0s 493us/step - loss: 0.1566 - acc: 0.9836 - val_loss: 0.4450 - val_acc: 0.5729\n",
      "Epoch 171/300\n",
      "365/365 [==============================] - 0s 554us/step - loss: 0.1425 - acc: 0.9973 - val_loss: 0.4423 - val_acc: 0.5833\n",
      "Epoch 172/300\n",
      "365/365 [==============================] - 0s 546us/step - loss: 0.1547 - acc: 0.9918 - val_loss: 0.4488 - val_acc: 0.5729\n",
      "Epoch 173/300\n",
      "365/365 [==============================] - 0s 530us/step - loss: 0.1571 - acc: 0.9836 - val_loss: 0.4470 - val_acc: 0.5521\n",
      "Epoch 174/300\n",
      "365/365 [==============================] - 0s 533us/step - loss: 0.1511 - acc: 0.9945 - val_loss: 0.4388 - val_acc: 0.5729\n",
      "Epoch 175/300\n",
      "365/365 [==============================] - 0s 532us/step - loss: 0.1481 - acc: 0.9945 - val_loss: 0.4375 - val_acc: 0.5938\n",
      "Epoch 176/300\n",
      "365/365 [==============================] - 0s 490us/step - loss: 0.1506 - acc: 0.9945 - val_loss: 0.4369 - val_acc: 0.5938\n",
      "Epoch 177/300\n",
      "365/365 [==============================] - 0s 513us/step - loss: 0.1527 - acc: 0.9890 - val_loss: 0.4299 - val_acc: 0.5833\n",
      "Epoch 178/300\n",
      "365/365 [==============================] - 0s 511us/step - loss: 0.1480 - acc: 0.9918 - val_loss: 0.4321 - val_acc: 0.5729\n",
      "Epoch 179/300\n",
      "365/365 [==============================] - 0s 528us/step - loss: 0.1483 - acc: 0.9945 - val_loss: 0.4409 - val_acc: 0.6146\n",
      "Epoch 180/300\n",
      "365/365 [==============================] - 0s 623us/step - loss: 0.1422 - acc: 0.9945 - val_loss: 0.4399 - val_acc: 0.5938\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 181/300\n",
      "365/365 [==============================] - 0s 486us/step - loss: 0.1522 - acc: 0.9918 - val_loss: 0.4346 - val_acc: 0.5833\n",
      "Epoch 182/300\n",
      "365/365 [==============================] - 0s 530us/step - loss: 0.1441 - acc: 0.9973 - val_loss: 0.4348 - val_acc: 0.5833\n",
      "Epoch 183/300\n",
      "365/365 [==============================] - 0s 547us/step - loss: 0.1552 - acc: 0.9973 - val_loss: 0.4397 - val_acc: 0.5729\n",
      "Epoch 184/300\n",
      "365/365 [==============================] - 0s 520us/step - loss: 0.1522 - acc: 0.9890 - val_loss: 0.4398 - val_acc: 0.5729\n",
      "Epoch 185/300\n",
      "365/365 [==============================] - 0s 522us/step - loss: 0.1431 - acc: 0.9890 - val_loss: 0.4428 - val_acc: 0.5729\n",
      "Epoch 186/300\n",
      "365/365 [==============================] - 0s 486us/step - loss: 0.1477 - acc: 0.9945 - val_loss: 0.4439 - val_acc: 0.5729\n",
      "Epoch 187/300\n",
      "365/365 [==============================] - 0s 545us/step - loss: 0.1319 - acc: 1.0000 - val_loss: 0.4441 - val_acc: 0.5833\n",
      "Epoch 188/300\n",
      "365/365 [==============================] - 0s 493us/step - loss: 0.1577 - acc: 0.9890 - val_loss: 0.4457 - val_acc: 0.5729\n",
      "Epoch 189/300\n",
      "365/365 [==============================] - 0s 609us/step - loss: 0.1487 - acc: 0.9945 - val_loss: 0.4504 - val_acc: 0.5938\n",
      "Epoch 190/300\n",
      "365/365 [==============================] - 0s 607us/step - loss: 0.1466 - acc: 0.9890 - val_loss: 0.4494 - val_acc: 0.5521\n",
      "Epoch 191/300\n",
      "365/365 [==============================] - 0s 481us/step - loss: 0.1475 - acc: 0.9918 - val_loss: 0.4524 - val_acc: 0.5521\n",
      "Epoch 192/300\n",
      "365/365 [==============================] - 0s 581us/step - loss: 0.1481 - acc: 0.9945 - val_loss: 0.4559 - val_acc: 0.5625\n",
      "Epoch 193/300\n",
      "365/365 [==============================] - 0s 1ms/step - loss: 0.1422 - acc: 1.0000 - val_loss: 0.4418 - val_acc: 0.5833\n",
      "Epoch 194/300\n",
      "365/365 [==============================] - 0s 514us/step - loss: 0.1384 - acc: 0.9945 - val_loss: 0.4408 - val_acc: 0.5938\n",
      "Epoch 195/300\n",
      "365/365 [==============================] - 0s 610us/step - loss: 0.1363 - acc: 0.9973 - val_loss: 0.4460 - val_acc: 0.5938\n",
      "Epoch 196/300\n",
      "365/365 [==============================] - 0s 721us/step - loss: 0.1514 - acc: 0.9863 - val_loss: 0.4362 - val_acc: 0.6042\n",
      "Epoch 197/300\n",
      "365/365 [==============================] - 0s 601us/step - loss: 0.1537 - acc: 0.9918 - val_loss: 0.4373 - val_acc: 0.5938\n",
      "Epoch 198/300\n",
      "365/365 [==============================] - 0s 738us/step - loss: 0.1436 - acc: 0.9918 - val_loss: 0.4384 - val_acc: 0.5938\n",
      "Epoch 199/300\n",
      "365/365 [==============================] - 0s 691us/step - loss: 0.1406 - acc: 0.9890 - val_loss: 0.4363 - val_acc: 0.6042\n",
      "Epoch 200/300\n",
      "365/365 [==============================] - 0s 572us/step - loss: 0.1512 - acc: 0.9945 - val_loss: 0.4360 - val_acc: 0.6146\n",
      "Epoch 201/300\n",
      "365/365 [==============================] - 0s 708us/step - loss: 0.1393 - acc: 0.9945 - val_loss: 0.4392 - val_acc: 0.5938\n",
      "Epoch 202/300\n",
      "365/365 [==============================] - 0s 862us/step - loss: 0.1453 - acc: 0.9945 - val_loss: 0.4400 - val_acc: 0.5625\n",
      "Epoch 203/300\n",
      "365/365 [==============================] - 0s 632us/step - loss: 0.1453 - acc: 0.9918 - val_loss: 0.4422 - val_acc: 0.5833\n",
      "Epoch 204/300\n",
      "365/365 [==============================] - 0s 606us/step - loss: 0.1404 - acc: 1.0000 - val_loss: 0.4404 - val_acc: 0.5938\n",
      "Epoch 205/300\n",
      "365/365 [==============================] - 0s 940us/step - loss: 0.1424 - acc: 0.9945 - val_loss: 0.4319 - val_acc: 0.5833\n",
      "Epoch 206/300\n",
      "365/365 [==============================] - 0s 938us/step - loss: 0.1389 - acc: 1.0000 - val_loss: 0.4323 - val_acc: 0.6042\n",
      "Epoch 207/300\n",
      "365/365 [==============================] - 0s 927us/step - loss: 0.1343 - acc: 0.9945 - val_loss: 0.4363 - val_acc: 0.5833\n",
      "Epoch 208/300\n",
      "365/365 [==============================] - 1s 2ms/step - loss: 0.1414 - acc: 0.9918 - val_loss: 0.4394 - val_acc: 0.5729\n",
      "Epoch 209/300\n",
      "365/365 [==============================] - 0s 1ms/step - loss: 0.1478 - acc: 0.9973 - val_loss: 0.4400 - val_acc: 0.5729\n",
      "Epoch 210/300\n",
      "365/365 [==============================] - 0s 1ms/step - loss: 0.1434 - acc: 0.9973 - val_loss: 0.4409 - val_acc: 0.5729\n",
      "Epoch 211/300\n",
      "365/365 [==============================] - 0s 808us/step - loss: 0.1436 - acc: 0.9945 - val_loss: 0.4375 - val_acc: 0.5833\n",
      "Epoch 212/300\n",
      "365/365 [==============================] - 0s 848us/step - loss: 0.1375 - acc: 0.9973 - val_loss: 0.4360 - val_acc: 0.5938\n",
      "Epoch 213/300\n",
      "365/365 [==============================] - 0s 825us/step - loss: 0.1427 - acc: 0.9890 - val_loss: 0.4321 - val_acc: 0.5729\n",
      "Epoch 214/300\n",
      "365/365 [==============================] - 0s 947us/step - loss: 0.1323 - acc: 1.0000 - val_loss: 0.4350 - val_acc: 0.5729\n",
      "Epoch 215/300\n",
      "365/365 [==============================] - 1s 1ms/step - loss: 0.1496 - acc: 0.9945 - val_loss: 0.4445 - val_acc: 0.6042\n",
      "Epoch 216/300\n",
      "365/365 [==============================] - 1s 3ms/step - loss: 0.1456 - acc: 0.9918 - val_loss: 0.4440 - val_acc: 0.5729\n",
      "Epoch 217/300\n",
      "365/365 [==============================] - 1s 3ms/step - loss: 0.1402 - acc: 0.9945 - val_loss: 0.4419 - val_acc: 0.5833\n",
      "Epoch 218/300\n",
      "365/365 [==============================] - 0s 1ms/step - loss: 0.1370 - acc: 0.9973 - val_loss: 0.4481 - val_acc: 0.5625\n",
      "Epoch 219/300\n",
      "365/365 [==============================] - 1s 1ms/step - loss: 0.1421 - acc: 0.9836 - val_loss: 0.4485 - val_acc: 0.5938\n",
      "Epoch 220/300\n",
      "365/365 [==============================] - 1s 2ms/step - loss: 0.1335 - acc: 1.0000 - val_loss: 0.4378 - val_acc: 0.6042\n",
      "Epoch 221/300\n",
      "365/365 [==============================] - 0s 827us/step - loss: 0.1499 - acc: 1.0000 - val_loss: 0.4394 - val_acc: 0.5938\n",
      "Epoch 222/300\n",
      "365/365 [==============================] - 0s 1ms/step - loss: 0.1346 - acc: 0.9890 - val_loss: 0.4451 - val_acc: 0.6250\n",
      "Epoch 223/300\n",
      "365/365 [==============================] - 1s 2ms/step - loss: 0.1424 - acc: 0.9945 - val_loss: 0.4394 - val_acc: 0.6042\n",
      "Epoch 224/300\n",
      "365/365 [==============================] - 0s 1ms/step - loss: 0.1346 - acc: 0.9973 - val_loss: 0.4381 - val_acc: 0.5313\n",
      "Epoch 225/300\n",
      "365/365 [==============================] - 0s 1ms/step - loss: 0.1418 - acc: 1.0000 - val_loss: 0.4459 - val_acc: 0.5833\n",
      "Epoch 226/300\n",
      "365/365 [==============================] - 0s 1ms/step - loss: 0.1395 - acc: 1.0000 - val_loss: 0.4508 - val_acc: 0.5729\n",
      "Epoch 227/300\n",
      "365/365 [==============================] - 1s 2ms/step - loss: 0.1406 - acc: 0.9890 - val_loss: 0.4465 - val_acc: 0.5938\n",
      "Epoch 228/300\n",
      "365/365 [==============================] - 1s 2ms/step - loss: 0.1465 - acc: 0.9945 - val_loss: 0.4436 - val_acc: 0.5625\n",
      "Epoch 229/300\n",
      "365/365 [==============================] - 0s 1ms/step - loss: 0.1383 - acc: 0.9945 - val_loss: 0.4464 - val_acc: 0.5938\n",
      "Epoch 230/300\n",
      "365/365 [==============================] - 1s 2ms/step - loss: 0.1441 - acc: 0.9945 - val_loss: 0.4446 - val_acc: 0.5938\n",
      "Epoch 231/300\n",
      "365/365 [==============================] - 0s 928us/step - loss: 0.1422 - acc: 0.9918 - val_loss: 0.4432 - val_acc: 0.5938\n",
      "Epoch 232/300\n",
      "365/365 [==============================] - 0s 1ms/step - loss: 0.1339 - acc: 0.9973 - val_loss: 0.4417 - val_acc: 0.5833\n",
      "Epoch 233/300\n",
      "365/365 [==============================] - 0s 904us/step - loss: 0.1445 - acc: 0.9973 - val_loss: 0.4387 - val_acc: 0.5938\n",
      "Epoch 234/300\n",
      "365/365 [==============================] - 1s 2ms/step - loss: 0.1269 - acc: 1.0000 - val_loss: 0.4394 - val_acc: 0.6146\n",
      "Epoch 235/300\n",
      "365/365 [==============================] - 0s 885us/step - loss: 0.1456 - acc: 0.9945 - val_loss: 0.4385 - val_acc: 0.6250\n",
      "Epoch 236/300\n",
      "365/365 [==============================] - 0s 830us/step - loss: 0.1390 - acc: 0.9918 - val_loss: 0.4347 - val_acc: 0.6250\n",
      "Epoch 237/300\n",
      "365/365 [==============================] - 0s 692us/step - loss: 0.1453 - acc: 0.9890 - val_loss: 0.4312 - val_acc: 0.6354\n",
      "Epoch 238/300\n",
      "365/365 [==============================] - 0s 708us/step - loss: 0.1321 - acc: 0.9890 - val_loss: 0.4342 - val_acc: 0.6354\n",
      "Epoch 239/300\n",
      "365/365 [==============================] - 0s 772us/step - loss: 0.1360 - acc: 0.9973 - val_loss: 0.4370 - val_acc: 0.5938\n",
      "Epoch 240/300\n",
      "365/365 [==============================] - 0s 1ms/step - loss: 0.1460 - acc: 0.9945 - val_loss: 0.4372 - val_acc: 0.5729\n",
      "Epoch 241/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "365/365 [==============================] - 0s 866us/step - loss: 0.1367 - acc: 0.9945 - val_loss: 0.4380 - val_acc: 0.5833\n",
      "Epoch 242/300\n",
      "365/365 [==============================] - 0s 753us/step - loss: 0.1323 - acc: 0.9973 - val_loss: 0.4398 - val_acc: 0.6146\n",
      "Epoch 243/300\n",
      "365/365 [==============================] - 0s 807us/step - loss: 0.1382 - acc: 0.9918 - val_loss: 0.4322 - val_acc: 0.5833\n",
      "Epoch 244/300\n",
      "365/365 [==============================] - 0s 969us/step - loss: 0.1385 - acc: 0.9890 - val_loss: 0.4332 - val_acc: 0.6042\n",
      "Epoch 245/300\n",
      "365/365 [==============================] - 0s 697us/step - loss: 0.1326 - acc: 1.0000 - val_loss: 0.4408 - val_acc: 0.6250\n",
      "Epoch 246/300\n",
      "365/365 [==============================] - 0s 753us/step - loss: 0.1408 - acc: 0.9945 - val_loss: 0.4407 - val_acc: 0.6354\n",
      "Epoch 247/300\n",
      "365/365 [==============================] - 0s 624us/step - loss: 0.1308 - acc: 0.9945 - val_loss: 0.4421 - val_acc: 0.6146\n",
      "Epoch 248/300\n",
      "365/365 [==============================] - 0s 608us/step - loss: 0.1424 - acc: 0.9973 - val_loss: 0.4451 - val_acc: 0.6042\n",
      "Epoch 249/300\n",
      "365/365 [==============================] - 0s 886us/step - loss: 0.1334 - acc: 1.0000 - val_loss: 0.4430 - val_acc: 0.5938\n",
      "Epoch 250/300\n",
      "365/365 [==============================] - 0s 979us/step - loss: 0.1393 - acc: 0.9945 - val_loss: 0.4434 - val_acc: 0.6250\n",
      "Epoch 251/300\n",
      "365/365 [==============================] - 0s 804us/step - loss: 0.1335 - acc: 1.0000 - val_loss: 0.4470 - val_acc: 0.6250\n",
      "Epoch 252/300\n",
      "365/365 [==============================] - 0s 792us/step - loss: 0.1404 - acc: 0.9945 - val_loss: 0.4392 - val_acc: 0.5938\n",
      "Epoch 253/300\n",
      "365/365 [==============================] - 0s 648us/step - loss: 0.1440 - acc: 0.9918 - val_loss: 0.4375 - val_acc: 0.5938\n",
      "Epoch 254/300\n",
      "365/365 [==============================] - 0s 937us/step - loss: 0.1350 - acc: 0.9890 - val_loss: 0.4442 - val_acc: 0.6146\n",
      "Epoch 255/300\n",
      "365/365 [==============================] - 0s 623us/step - loss: 0.1259 - acc: 0.9918 - val_loss: 0.4452 - val_acc: 0.6146\n",
      "Epoch 256/300\n",
      "365/365 [==============================] - 0s 641us/step - loss: 0.1465 - acc: 0.9973 - val_loss: 0.4431 - val_acc: 0.5833\n",
      "Epoch 257/300\n",
      "365/365 [==============================] - 0s 622us/step - loss: 0.1440 - acc: 0.9945 - val_loss: 0.4433 - val_acc: 0.5729\n",
      "Epoch 258/300\n",
      "365/365 [==============================] - 0s 633us/step - loss: 0.1314 - acc: 0.9945 - val_loss: 0.4439 - val_acc: 0.6042\n",
      "Epoch 259/300\n",
      "365/365 [==============================] - 0s 643us/step - loss: 0.1324 - acc: 0.9945 - val_loss: 0.4464 - val_acc: 0.6146\n",
      "Epoch 260/300\n",
      "365/365 [==============================] - 0s 720us/step - loss: 0.1294 - acc: 0.9945 - val_loss: 0.4458 - val_acc: 0.6354\n",
      "Epoch 261/300\n",
      "365/365 [==============================] - 0s 616us/step - loss: 0.1394 - acc: 0.9945 - val_loss: 0.4467 - val_acc: 0.6146\n",
      "Epoch 262/300\n",
      "365/365 [==============================] - 0s 804us/step - loss: 0.1366 - acc: 0.9945 - val_loss: 0.4441 - val_acc: 0.6042\n",
      "Epoch 263/300\n",
      "365/365 [==============================] - 0s 601us/step - loss: 0.1494 - acc: 0.9863 - val_loss: 0.4419 - val_acc: 0.5938\n",
      "Epoch 264/300\n",
      "365/365 [==============================] - 0s 779us/step - loss: 0.1447 - acc: 0.9973 - val_loss: 0.4419 - val_acc: 0.5938\n",
      "Epoch 265/300\n",
      "365/365 [==============================] - 0s 869us/step - loss: 0.1395 - acc: 0.9890 - val_loss: 0.4433 - val_acc: 0.6042\n",
      "Epoch 266/300\n",
      "365/365 [==============================] - 0s 1ms/step - loss: 0.1287 - acc: 0.9945 - val_loss: 0.4450 - val_acc: 0.6146\n",
      "Epoch 267/300\n",
      "365/365 [==============================] - 0s 753us/step - loss: 0.1391 - acc: 0.9973 - val_loss: 0.4470 - val_acc: 0.6146\n",
      "Epoch 268/300\n",
      "365/365 [==============================] - 0s 777us/step - loss: 0.1416 - acc: 0.9890 - val_loss: 0.4468 - val_acc: 0.6042\n",
      "Epoch 269/300\n",
      "365/365 [==============================] - 0s 777us/step - loss: 0.1342 - acc: 0.9945 - val_loss: 0.4449 - val_acc: 0.5938\n",
      "Epoch 270/300\n",
      "365/365 [==============================] - 0s 720us/step - loss: 0.1218 - acc: 0.9945 - val_loss: 0.4416 - val_acc: 0.5833\n",
      "Epoch 271/300\n",
      "365/365 [==============================] - 0s 936us/step - loss: 0.1293 - acc: 1.0000 - val_loss: 0.4389 - val_acc: 0.5521\n",
      "Epoch 272/300\n",
      "365/365 [==============================] - 0s 869us/step - loss: 0.1362 - acc: 0.9973 - val_loss: 0.4404 - val_acc: 0.5729\n",
      "Epoch 273/300\n",
      "365/365 [==============================] - 0s 666us/step - loss: 0.1377 - acc: 0.9945 - val_loss: 0.4446 - val_acc: 0.5938\n",
      "Epoch 274/300\n",
      "365/365 [==============================] - 0s 568us/step - loss: 0.1363 - acc: 1.0000 - val_loss: 0.4418 - val_acc: 0.5833\n",
      "Epoch 275/300\n",
      "365/365 [==============================] - 0s 572us/step - loss: 0.1336 - acc: 1.0000 - val_loss: 0.4369 - val_acc: 0.5938\n",
      "Epoch 276/300\n",
      "365/365 [==============================] - 0s 559us/step - loss: 0.1375 - acc: 0.9890 - val_loss: 0.4403 - val_acc: 0.5833\n",
      "Epoch 277/300\n",
      "365/365 [==============================] - 0s 628us/step - loss: 0.1438 - acc: 1.0000 - val_loss: 0.4456 - val_acc: 0.5729\n",
      "Epoch 278/300\n",
      "365/365 [==============================] - 0s 544us/step - loss: 0.1337 - acc: 0.9890 - val_loss: 0.4509 - val_acc: 0.5938\n",
      "Epoch 279/300\n",
      "365/365 [==============================] - 0s 596us/step - loss: 0.1431 - acc: 0.9973 - val_loss: 0.4567 - val_acc: 0.5833\n",
      "Epoch 280/300\n",
      "365/365 [==============================] - 0s 572us/step - loss: 0.1432 - acc: 0.9973 - val_loss: 0.4516 - val_acc: 0.5938\n",
      "Epoch 281/300\n",
      "365/365 [==============================] - 0s 674us/step - loss: 0.1337 - acc: 0.9918 - val_loss: 0.4480 - val_acc: 0.6042\n",
      "Epoch 282/300\n",
      "365/365 [==============================] - 0s 589us/step - loss: 0.1292 - acc: 0.9973 - val_loss: 0.4457 - val_acc: 0.6250\n",
      "Epoch 283/300\n",
      "365/365 [==============================] - 0s 559us/step - loss: 0.1343 - acc: 0.9973 - val_loss: 0.4411 - val_acc: 0.5938\n",
      "Epoch 284/300\n",
      "365/365 [==============================] - 0s 575us/step - loss: 0.1386 - acc: 1.0000 - val_loss: 0.4407 - val_acc: 0.5833\n",
      "Epoch 285/300\n",
      "365/365 [==============================] - 0s 565us/step - loss: 0.1328 - acc: 0.9945 - val_loss: 0.4433 - val_acc: 0.5938\n",
      "Epoch 286/300\n",
      "365/365 [==============================] - 0s 558us/step - loss: 0.1333 - acc: 0.9973 - val_loss: 0.4441 - val_acc: 0.5833\n",
      "Epoch 287/300\n",
      "365/365 [==============================] - 0s 615us/step - loss: 0.1304 - acc: 1.0000 - val_loss: 0.4477 - val_acc: 0.6042\n",
      "Epoch 288/300\n",
      "365/365 [==============================] - 0s 631us/step - loss: 0.1408 - acc: 0.9918 - val_loss: 0.4499 - val_acc: 0.5729\n",
      "Epoch 289/300\n",
      "365/365 [==============================] - 0s 597us/step - loss: 0.1234 - acc: 0.9945 - val_loss: 0.4522 - val_acc: 0.5938\n",
      "Epoch 290/300\n",
      "365/365 [==============================] - 0s 555us/step - loss: 0.1369 - acc: 1.0000 - val_loss: 0.4537 - val_acc: 0.6042\n",
      "Epoch 291/300\n",
      "365/365 [==============================] - 0s 594us/step - loss: 0.1329 - acc: 0.9945 - val_loss: 0.4539 - val_acc: 0.5938\n",
      "Epoch 292/300\n",
      "365/365 [==============================] - 0s 578us/step - loss: 0.1381 - acc: 0.9973 - val_loss: 0.4552 - val_acc: 0.5729\n",
      "Epoch 293/300\n",
      "365/365 [==============================] - 0s 536us/step - loss: 0.1164 - acc: 0.9973 - val_loss: 0.4541 - val_acc: 0.5521\n",
      "Epoch 294/300\n",
      "365/365 [==============================] - 0s 575us/step - loss: 0.1327 - acc: 1.0000 - val_loss: 0.4515 - val_acc: 0.5521\n",
      "Epoch 295/300\n",
      "365/365 [==============================] - 0s 636us/step - loss: 0.1296 - acc: 0.9918 - val_loss: 0.4514 - val_acc: 0.5833\n",
      "Epoch 296/300\n",
      "365/365 [==============================] - 0s 562us/step - loss: 0.1426 - acc: 0.9973 - val_loss: 0.4545 - val_acc: 0.6146\n",
      "Epoch 297/300\n",
      "365/365 [==============================] - 0s 636us/step - loss: 0.1416 - acc: 0.9918 - val_loss: 0.4496 - val_acc: 0.6354\n",
      "Epoch 298/300\n",
      "365/365 [==============================] - 0s 578us/step - loss: 0.1375 - acc: 0.9945 - val_loss: 0.4499 - val_acc: 0.6458\n",
      "Epoch 299/300\n",
      "365/365 [==============================] - 0s 594us/step - loss: 0.1380 - acc: 0.9973 - val_loss: 0.4543 - val_acc: 0.6250\n",
      "Epoch 300/300\n",
      "365/365 [==============================] - 0s 665us/step - loss: 0.1401 - acc: 0.9973 - val_loss: 0.4512 - val_acc: 0.6042\n"
     ]
    }
   ],
   "source": [
    "from keras import *\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "\n",
    "# design network\n",
    "model = Sequential()\n",
    "model.add(LSTM(150, input_shape=(trainX.shape[1], trainX.shape[2]),return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(150,return_sequences=False))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mae', optimizer='adam', metrics=['accuracy'])\n",
    "# fit network\n",
    "\n",
    "history = model.fit(trainX,\n",
    "                    trainY,\n",
    "                    epochs=300,\n",
    "                    batch_size=80,\n",
    "                    validation_data=(testX, testY), verbose=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzsnXl4VOX5v+8z2ROy7wshAUIg7DuyKSoKiqB1qQu1ai3a\nqt1+ttXWr7V2s7u1Wq1aWxX3laAogoqg7CCBkBACgexk38k6c35/vJmZLJNkJpnsz31dcyVzznvO\nvJPMfM5znvdZNF3XEQRBEEYWhsGegCAIguB8RNwFQRBGICLugiAIIxARd0EQhBGIiLsgCMIIRMRd\nEARhBCLiLgiCMAIRcRcEQRiBiLgLgiCMQFwH64VDQkL0uLi4wXp5QRCEYcmhQ4dKdV0P7WncoIl7\nXFwcBw8eHKyXFwRBGJZompZtzzhxywiCIIxARNwFQRBGICLugiAII5BB87nborm5mby8PBoaGgZ7\nKv2Kp6cnMTExuLm5DfZUBEEYoQwpcc/Ly8PX15e4uDg0TRvs6fQLuq5TVlZGXl4e8fHxgz0dQRBG\nKEPKLdPQ0EBwcPCIFXYATdMIDg4e8XcngiAMLkNK3IERLexmRsN7FARhcBly4i4IgjCSON/Uwsa9\n2VSebxrQ1xVxb0NlZSX/+te/HD7uiiuuoLKysh9mJAjCcCav4jzXPb2Hh95P5e6Nh2g2mgbstUXc\n29CVuBuNxm6P27JlCwEBAf01LUEQhiH7sspY++RX5Fac544l8ezNKufRzWkD9vpDKlpmsHnggQc4\nffo0s2bNws3NjTFjxhAZGcmRI0dIS0vj6quvJjc3l4aGBn74wx+yYcMGwFpKoba2ltWrV7N06VJ2\n795NdHQ0mzZtwsvLa5DfmSAIA8mJc9Xc8vw+YoO9ee7WeUwIHYObi8a/d2aRGOHL+kXj+n0OQ1bc\nf735OGkF1U49Z1KUH7+6amqX+x977DFSU1M5cuQIO3bs4MorryQ1NdUSsvjCCy8QFBREfX098+fP\n59prryU4OLjdOTIzM3nttdd47rnnuOGGG3jnnXdYv369U9+HIAhDm7cO5mHQNN666wKCx3gA8LNV\nkzlZVMMjyceZGDaGReODezhL3xC3TDcsWLCgXSz6E088wcyZM1m0aBG5ublkZmZ2OiY+Pp5Zs2YB\nMHfuXM6ePTtQ0xUEYQhgNOlsTingosRQi7ADuBg0/nHTbKbH+NPU0v++9yFruXdnYQ8UPj4+lt93\n7NjB9u3b2bNnD97e3lx00UU2Y9U9PNr8M11cqK+vH5C5CoLQf9Q3GSmrayQm0LvHsfuyyiiuaWTd\nrOhO+/w83Xj3e4sHJBxaLPc2+Pr6UlNTY3NfVVUVgYGBeHt7c+LECfbu3TvAsxMEYbD409YTXPnE\nlxhNeo9jNx0pwMfdhUumhNncP1B5LkPWch8MgoODWbJkCdOmTcPLy4vw8HDLvlWrVvHMM88wY8YM\nEhMTWbRo0SDOVBCEgULXdT5OPUdVfTNny+qYEDqmy7GNLUa2pBZy+bQIPN1cBnCWnRFx78Crr75q\nc7uHhwcfffSRzX1mv3pISAipqamW7ffff7/T5ycIwsCSml9NYZVywWacq+lW3D8/UUJNQwtX23DJ\nDDTilhEEQeiGbelFGDQwaHDinG23rZnklHxCxrizeEL/RsLYg4i7IAhDimajiTOldQP2eqW1jZTV\nNna5f1taEXPHBRIX7EPGua7Ds2samtmeXsyaGVG4ugy+tA7+DARBENrw4u6zXPb3L7oVXGeh6zrr\nn9/H7f87gK53XizNLT9PemE1K5PCSYzwJaMby/3v2zJpajGxblZUf07ZbkTcBUEYUnyaXkyzUedo\nXpXTzmk06az55y7++klGu+37zpRz4lwNR/OqOJLbuT7Up+lFAKxMiiAxwpfs8vOcb2rpNO7Ng7m8\n8NUZblscx+zYQKfNuy+IuAuCMGQ439TCwexyAFLynFeM74uTxaTmV/PsziyKa6z5KRv3ZuPn6YqP\nuwsb9+Z0Om5behETw8YQH+LD5AhfdB0yi2rbjTmUXc5D76WydGIID105xWlz7isi7oIgDBn2ZZXT\nbNRxNWgcc6LlvnFvDgHebjQbTTy3MwuAkppGth4/x3Vzx3LNnGg+OFrQrixvVX0z+7LKWZmkQqIT\nI/wA2rlmzlU1cNfLh4kM8OTJm2cPCV+7maEzkyFAb0v+Ajz++OOcP3/eyTMShNHFzswSPFwNrJoW\nQUpelU0/uKPklp/n84xi1i8cx7pZ0Wzcm0NpbSNvHsyl2ahzy6JYblk4jsYWE28fyrMctyOjmBaT\nbhH32CBvPN0M7SJm/rv7DBXnm3j+1nkEeLv3ea7ORMS9DSLugjC47MosZUF8EAvigyitbbTEl/eF\n1/bnoAE3LYzlnhUTaWgx8uzOLF7dl8PiCcFMCB3DlEg/5o4L5JV9OZhMOsfyqnjsoxNE+HkyK0aV\n83YxaEwK9yWjSEXMmEw6m48UsDwhhIRw3z7P09mIuLehbcnfn/70p/z5z39m/vz5zJgxg1/96lcA\n1NXVceWVVzJz5kymTZvGG2+8wRNPPEFBQQErVqxgxYoVg/wuBGF4UlBZz6niWpYnhDI92h+gy0XV\nI7mVzPz1JxzOqWi3vaq+meV/+pz/ez+VphYTTS0m3jyYy8WTw4kO8GJi2BjWzIjiuV1Z5FfWtyu9\nu35RLGdK63j0gzSue2Y3Bk3jP7fNw2CwlgtIDLdGzBzMrqCgqsFmDZmhwNDNUP3oATh3zLnnjJgO\nqx/rcnfbkr+ffPIJb7/9Nvv370fXddauXcvOnTspKSkhKiqKDz/8EFA1Z/z9/fnb3/7G559/TkhI\niHPnLAgjlO1pRXyWUcyv107FzcXAl5mlACybFEJcsA+uBo2jeZWsmhbR7rgWo4lfvHuMqvpm3tif\ny5w20SlbU8+RU36el/dmk1FUwxXTIiitbWL9oljLmPsunsjmlALCfD0sLheA1dMieXRzGv/bfZYF\n8UE8fcucdlUdARIjfHnrUB6ltY1sOpKPl5tLu3MMJYauuA8yn3zyCZ988gmzZ88GoLa2lszMTJYt\nW8b999/Pz3/+c9asWcOyZcsGeaaCMDzZlFLA5pQC3F0MPLJ2KjszSwj19SAx3BdN00iM8OVYfmfL\n/aU92aQVVjMu2JstqYU8evVUPFxdWs+ZT1ywNz+6dBI/f+co+8+UExvkzfKEUMvxk8J9eWD1ZGIC\nvXBrswDq6ebCr9dNI6uklntWTGy3z8zk1kXV1PwqPjxWyMqkcHw8hqaMDs1ZQbcW9kCg6zoPPvgg\nd911V6d9hw4dYsuWLTz44INcdtllPPzww4MwQ0EY3uRVnMfFoPG/3WdJCB/Dl6dKuXhymKVq4owY\nf7YcO4eu65Zt56oa+OsnGVyUGMq3F8dx+38PsCOjhMunRlBc3cCe02Xcu2IiV8+OZkLoGO5/K4U7\nl8W3c60A3H3hBJtzWjuz+wSkxAjlW39+1xkqzzcPmYQlW4jPvQ1tS/5efvnlvPDCC9TWqpjW/Px8\niouLKSgowNvbm/Xr13P//fdz+PDhTscKgtAz+RX1XD0rmuWTQnno/VQqzze3s7BnxARQVd9Mdpk1\nUOHRD47TYtJ5dO00lk4MIdjHneQjBQB8cLQQkw5rWwV3eow/W3+8nOvnjXXanEN9PQj2cefLU6UE\neLuxrM18hxoi7m1oW/J327Zt3HzzzVxwwQVMnz6d6667jpqaGo4dO8aCBQuYNWsWv/vd73jooYcA\n2LBhA6tXr5YFVUGwg4ZmI8U1jYwL9uafN80mPlg1xlky0bpmZVlUbXXNfHC0gC3HznHfxROJDfbG\nzcXAlTMi2Z5eRE1DM5tSCpga5cfEsP6NXDFb71dMj8TddehK6NB1ywwSHUv+/vCHP2z3fMKECVx+\n+eWdjrvvvvu47777+nVugjBSMIc4Rgd44e/lxst3LiQ1v4pQX+sCZmKEL+6uBo7mVjI+xIf730ph\n7rhANiy3ulTWzYripT3ZPLczi5TcSn5xxeR+n3tihC+7T5exrgcXzmAj4i4IwoCTV6FcLTGBXoAS\n+egAr3Zj3FwMJEX68eWpUrYcKyTQ251n1s9tZy3PiQ0kJtCLJz8/habBVQMguNfNjcGgacyPC+r3\n1+oLQ/eeQhCEIU92WR11jZ0LafVEfoXqLRwd6NXtuJkx/pw4V0P5+Saeu3VeO8seVMu6tTOjMOmw\nIC6ISP/uz+cMpkb5839rkjot0g41hpy4OyPdeKgzGt6jMPJpaDay5okv+f2WdIePzauox8WgEeHn\n2e24+fHKOv7zdTOZ1uqD78g1s6NxMWhcOzfG4XmMZIaUuHt6elJWVjaixU/XdcrKyvD07P5DLQhD\nnYNnK6hpbOGDo4U0thgdOjav4jwRfp49Ftq6Ylokux+4uFt3S0K4L7t+toLrRdzbMaR87jExMeTl\n5VFSUjLYU+lXPD09iYmRD6IwvNmVqb6nVfXN7DxZ6lCmZn5lvcXf3h0Gg0ZUQM/j7Bkz2rBL3DVN\nWwX8A3ABntd1/bEO+2OBF4GA1jEP6Lq+xdHJuLm5ER8f7+hhgiAMAjszS5kfF8jpkjo2Hcl3SNzz\nKuq5YAj0GR3J9OiW0TTNBXgKWA0kATdpmpbUYdhDwJu6rs8GbgR6V1pREIRhQXFNA+mF1ayYHMaV\n01WseW0XC6ultY2U1Fhb5jW1mCiqbiAm0HugpjsqscfnvgA4pet6lq7rTcDrwLoOY3TAr/V3f6DA\neVMUBGGo8dUpVeRreUIo62ZF0dBsYlvauU7jPs8oZsVfdrDh5YOWbeeqGjDpECOulH7FHnGPBnLb\nPM9r3daWR4D1mqblAVsAyeYRhBHMrpOlBPm4kxTpx5zYQKIDvNh0xGrT6brOM1+c5o7/HaCxxcSR\n3Eqq6psByKtsH+Mu9A/2iLutYM6O4Sw3Af/TdT0GuAJ4WdO0TufWNG2DpmkHNU07ONIXTQVhpNDQ\nbOR7Gw+xN6sMUMK9M7OUpRNDMBg0DAaNdbOi2JVZSklNI7syS7j9fwd47KMTXDE9kmfWz0HX4eBZ\n1Rs1z84Yd6Fv2LOgmge0rbwTQ2e3y3eAVQC6ru/RNM0TCAGK2w7Sdf1Z4FmAefPmjdx4R0EYQRzK\nruCj1HPsPl1G8r1LON9kpLS2kWUJ1jow62ZF868dp7n4rzuoaWgh0NuNX14xhTuXxdPYYsLdxcC+\nM+VcMiWc/Ip6NI0BSTgazdgj7geABE3T4oF81ILpzR3G5ACXAP/TNG0K4AmIaS4II4B9WWUYNNA0\nuPPFg6xubZ7RtiJiYoQvl04Jo7qhhVsWxrJqWoSlxrqnmwszx/qzr9Xyz6uoJ9zXc0gX3RoJ9Cju\nuq63aJp2L7AVFeb4gq7rxzVNexQ4qOt6MvD/gOc0TfsxymVzmz6SM5EEYRSx90w5U6P8efCKyXzr\nP/t54rNTTAofQ4R/+0S85789v8tzLIwP5ukvTlPb2EJ+5Xnxtw8Adl06dV3fouv6JF3XJ+i6/rvW\nbQ+3Cju6rqfpur5E1/WZuq7P0nX9k/6ctCAIA0NDs5EjuZUsGh/E4gkhPHKVioJe7mAd84XjgzCa\ndA6eLSevol787QPAkMpQFQShb7z/dT4ni2r42SrnlL49kltJU4uJhfEq4Wj9onGE+noyLy6whyPb\nM3dcIK4GjT2nyzhX1SCW+wAgTi9BGCE0G0384aN0XvjqDCaTc7yi+7LK0TRrAS9N01g1LYKQDo2j\ne8Lb3ZXpMf5sTimgxaQTHSAJTP2NiLsgjBA+TS+iqLqRhmYTRTUNXY5rNpr4OqcCox0XgH1nypgS\n4Ye/l1uf57cwPpiC1iYdYrn3PyLugjBC2Lg3B3OJ8TOldV2Oe2lPNtf8azfL/vgZT3yaSVG17QtB\nU4uJwzkVLBzvnKYUbc8jPvf+R8RdEEYAZ0rr+PJUKd+cH2t53hUfpxYyNsiLCWFj+Nu2kyz942e8\nui+n07ijeZU0NFv97X1l3rhAXFqvPh27LgnOR8RdEEYAr+zNxtWg8aNLE3B3NXC2C3Evq23kUHYF\n18yO4eXvLOSLn17E4gkh/OK9Yzz0/jGaWkyWsfvOqIzSBfHOsdx9Pd2YFuVHyBgPPN1cnHJOoWtE\n3AVhiFJc3cDzu7JIL6zudlxDs5G3DuVx+bQIwv08GRfkzZnS8zbHfnqiGJMOl7WW5x0X7MMLt83n\nrgvHs3FvDuuf38eR3Ep0XWdvVhmJ4b4E+bg77T398NIEfrwywWnnE7pGQiEFYYhxOKeC53ZmsS2t\niBaTztKJIWy8c2GX4zenFFBV38z6heMAiAvx6dItsy2tiEh/T6ZG+Vm2uRg0Hlw9haRIP37x7jGu\nfuorpkb5kVVSx/XznNtU5uLJ9td8F/qGiLsgDCGaWkysf34f7q4G7lgaT01DM28cyKW4uoEwG/1G\ndV3nha/OMjFsDItaFyzjQ3z4IqMEo0m3+LhBWfi7Mku4fu5YNK1zPcB1s6K5eHIY7x8p4JW92dQ3\nG7ko0bFkJWHoIOIuCEOInPLznG8y8turp/GNOTGcKq7htf25fHC0kDuWdu5Stj29mPTCav56/UyL\nYMcF+9BkNFFQWc/YIGs8+ZeZpTQ0m7rtmOTr6ca3Fo1j/cJYiqobO5UYEIYP4nMXhCGEeSE0PsQH\ngIlhvkyN8mNTSuf+N7qu88SnmcQGebNulrWBtPnYs2XtXTPb0orw9XBl0fieo180TRNhH+aIuAvC\nEMIsyGaBBlg3K4qU3MpOETA7Mko4ll/FvSsm4upi/SpbxL3NeKNJ59MTRVyYGCrVGEcJ8l8WhCFE\nVmkdAd5uBHhbI1SumhmFpkFySvtOR//4NJPoAC+umdO+MVq4nwdebi7tImaO5FZSWtvkUBNrYXgj\n4i4IQ4izpXXEBfu02xbp78WCuCDeP5KPuZL2rsxSjuRWcs+Kibi5tP8aa5rGuGDvdm6Zj1MLcTVo\nXJQY1v9vQhgSiLgLwhDibGldO5eMmXWzoskqqWPr8SL+9PEJfvTGEaL8Pbluru1QxfgQH4tbxmTS\n2ZxSyEWJoU6pESMMD0TcBWGI0NBspKCqoZPlDrB6WgRuLhp3bzzEM1+cZu64QJ69dV6X/vO4EB9y\nys/TYjSx/2w556obWDurY197YSQjoZCCMETILlM+8riQzuVwA33c+b81SZTXNfHN+WN77D8aH+xD\ni0knv7KeTUcK8HZ34dIp4pIZTYi4C8IQ4Uxp50iZttx6QZzd54prPcfJolq2HCvksqRwvN3l6z6a\nELeMIAwRzAugcV2IuyOYLxAv7j5LVX0z68QlM+oQcReEIcLZ0jqCfdzx8+z7omfIGHfGeLjy5alS\nAr3dWJoQ4oQZCsMJuU8ThAEir+I897+VQuX5ZgDcXAw8du10pkb5AyrG3RlWO6hwyLgQb1Lzq7ly\nRmSncElh5CP/cUEYAHRd5+FNxzmaV8W4YG/GBXuTWVzDxr3ZljG2Ytz7gvlc4pIZnYi4C4KTMZl0\njuZVWhKOALYeL+KzE8X8ZOUk/v2tefz7W/NYNTWCLcfO0dhipK6xheKaRuJtRMr0lkunhLN8Uihz\nYwOddk5h+CDiLghO5p3Deax98it+8mYKDc1KuH+9+TiTI3y5bXGcZdy6WdFU1Tez82SpUxdTzVw9\nO5qX7liAwdC5vK8w8hGfuyA4mUPZFbi5aLz3dT6nS2pJDPelsKqBJ2+e067A19KEEIJ83Nl0JJ/V\n0yIBnOqWEUY3YrkLgpM5mlfFovHBPPutuZwuruWtQ3nctCCWuePau0fcXAxcOT2S7elFHC+oApxr\nuQujGxF3Qegl6YXVvNxmQRRUCYGMohpmxPhz2dQI3rtnCbcvieOBVZNtnmPdrCgamk28si+HMF8P\nxnjIzbTgHOSTJAi9oLCqnltf2E9JTSMrp4RbGlukFVZjNOnMiAkAYFK4L7+6amqX55kTG0h0gBf5\nlfUsiA8akLkLowOx3IVRR4vR1C6Spe12k6nz9o40NBvZ8NIhqlrj1Xdlllj2Hc2tBGBGjL9dczEY\nNNa2dlGKF3+74ERE3IVRha7rrPjrDh77+ES77c1GE9f8azc/efNIj8f/7O2jpBZU8dQtcwgZ48Gu\nzFLL/qP5VYT6ehBho5l1V5hb5E0IE3EXnIeIuzCqOFfdQG55Pc/tzCI1v8qy/b9fneFYfhWbjxZy\nrqrB5rEmk84fPjpBckoB91+WyMqkcJYnhPDlqVKLxX80r4oZ0f6WZtX2MDnCj5e/s4CbFsT27c0J\nQhtE3IVRRWZRLQAGTeOX7x3D2FoW9+/bMpk7LhCTrvPa/pxOx9U0NLPh5YM8uzOLWxbG8v2LJgCw\nbFII5XVNpBVWU9vYwumSWou/3RGWJYTi64SaMoJgRsRdGFVkFitx/8UVU0jJq+LV/Tk8knwcgH/c\nOIvlCaG8fiCHZqPJcszZ0jqu+dduPs8o4dF1U/nt1dMslvmSiaog187MElLzq9B1mDHWPn+7IPQn\nIu7CsMRox8KnLU4V1xDk487tS+JYMjGY33yQxra0In54aQIxgd6sXzSOoupGPk0vAqC0tpFbnt9H\nWW0jG7+zkFsviGvncgnz9WRKpB+7TpZyLE+5eWZEi7gLg4+IuzDs+OJkCVN/9TH5lfUOH5tZVMvE\nsDFomsZv1k0DHSaFj+E7S+MBuHhyGFH+nmzcm0NTi4nvbzxMaW0jL96xgAsmBNs85/KEEA5ml7M3\nq4zoAC+Cx3j06f0JgjMQcReGFB+nnuPnbx/tdszr+3NoaDZx4Ey5Q+fWdZ3M4loSwsYAMD50DG9/\n7wJe/s5CS0lcF4PGTQti+fJUKd9/5TD7z5bzp+tmdOtHX5YQSrNR57OMYrtDIAWhvxFxF4YUrx/I\n4Y2DuRTX2I5YqW5o5tMTxYCKTHGEktpGquqbLeIOMCMmgPAOYYvfXDAWV4PG9vQivn/RhB5L5s6L\nC8TD1aD87b1YTBWE/sAucdc0bZWmaRmapp3SNO0BG/v/rmnakdbHSU3TKp0/VWGkYzLpfJ2jPjqH\ns21/hD5OPUdTi4lAbzeO5jn2MTvVGimTEO7b7bgwX082LB/PjfPHcv9liT2e19PNhYXjlctmplju\nwhChx/IDmqa5AE8BK4E84ICmacm6rqeZx+i6/uM24+8DZvfDXIURTlZpHVX1Kuvz65wKVk2L6DQm\n+UgB44K9WZEYxhsHcmkxmtpVWmxLx33mSJm2lntX/KyLWjBdcfnUcA5nVzBNxF0YIthjuS8ATum6\nnqXrehPwOrCum/E3Aa85Y3LC6OJwdgUAIWM8ONT6e1uKqxvYfbqUdTOjmDnWn/pmI6dKam2e640D\nOUx7ZCsfHSu0bMssrsHP05VQX+cveN68IJbdD17slP6nguAM7CkcFg3ktnmeByy0NVDTtHFAPPBZ\nF/s3ABsAYmMlG2808MA7R9l/1rrwee2cGO5ZMdHm2MM5Ffh5urJuVhQv782mqcWEu6vV/vjgaCEm\nHdbOirKEIx7Nq2JyhJ9lTLPRxG8/SOPFPapa4yv7clg9XdVKzyyqJSHc16HsUXvRNE2EXRhS2GO5\n2/omdBVkfCPwtq7rRls7dV1/Vtf1ebquzwsNDbV3jsIwZf+Zcl4/kEvIGA+SIv3w93Ljz1szbFrl\noMR9zrhA5o4LpKnFRFphdbv9m1IKmBrlx8QwX+KDffD1cG3nd29oNnLrf/bz4p5svrssnu9dNIHd\np0sprlaLs6faRMoIwkjHHnHPA8a2eR4DFHQx9kbEJSO08s/PMgkZ486Lty/gyZvnsPE7C4n09+SX\n7x2jpU0GKEBVfTMni2qZExtoaWrR9iJwtrSOlNxKS5Etg0FjWrS/JXEI4P2v89mTVcYfvjGdX16Z\nxLVzojHpyuIvq22krK6JiSLuwijBHnE/ACRomhavaZo7SsCTOw7SNC0RCAT2OHeKwnDkUHYFuzJL\n2bB8PF7uLgD4eLjyq6umcuJcDf/bfbbd+COtpXLnxAYS7udJdIAXh3Os4v7KvmwMGqyZEWXZNiPG\nn/TCGppaVAnfjfuySQz35cb5yhaZGOZLUqQfm1IKOFVsX6SMIIwUehR3XddbgHuBrUA68Kau68c1\nTXtU07S1bYbeBLyu2yqULYw6/vlZJkE+7tyycFy77ZdPDeeSyWH8bdtJCtpkmB7OrsCgwczWuiyz\nYwP4utVyL6ttZOPeHNbNiiYqwMtyzIyYAJqMJjLO1ZCSV0VqfjXrF8W286lfPTuKlNxKtreWE5gU\nLpa7MDqwK85d1/Utuq5P0nV9gq7rv2vd9rCu68ltxjyi63qnGHhh9JGSW8mOjBLuXBaPT4e2cZqm\n8cjaqZh0nYfeT7WUyj2cU8GkcF9LZcQ5sYEUVDVQWFXP81+eoaHF2Gkh1pwNmpJXyca92Xi7u3D1\n7PYJR1fNjELT4KU92YzxcHWozrogDGckQ1VwOv/8LJMAbzduvSDO5v6xQd48sGoyn50o5vFPMzGZ\ndI7kVDKnTQNps9/9sxPFvLT7LGtmRHXyl8cEehHo7cauzBI2pxRw9ezoTmVzI/29WBAXRGOLyVJT\nRhBGA9JDVXAq9U1GPs8o4c6l8d02e/724jiOF1TzxKeZaEBNYwtzY63iPiXSDw9XA49tOUFdk5H7\nLu4cPqlpGjNiAth6XLlc1ndwAZlZNyuafWfKJVJGGFWI5S44FXOD6LZWuC00TeO310xjTmwA//g0\nE6DdMe6uBmbE+FPT2MIV0yOY1MVCqNk1Myc2gKQoP5tjrpgega+nK7Nju5+TIIwkRNwFp2KOO59p\nRwEtD1cXnvnWXCL9PQn2cScu2Lvd/nlxQQDcuyKhy3PMjlWvs36RbasdIMDbnT0PXmKJohGE0YC4\nZQSnciyvijBfDyL87Vu4DPP15M27LqC8rqmTP/zu5RO4cFJolxY5wEWTwvjvbfO5cFL3SXHduYgE\nYSQilvsw5PX9ObyyL5vaxpY+nSe7rI5/7ThliVhxBil5lQ7XNB8b5M3MsZ0tfX9vNxaNt90gw4zB\noLFichgGgyyUCkJbxJwZZpwsquHB946h6/D7D9O5enY096yY2C7+215e3ZfDv3dm4e/l1ikevTfU\nNDSTVVqIx6MHAAAgAElEQVTXY/1zQRD6H7HchxlPfnYKbzcXXrpjAaunR/LWoTwe3pTaq3OltPrH\n//jRCUprG/s8t9T8anQdpkvZW0EYdETchxGnimvZfLSAWxfHsXxSKH+5fiZXzYgixcGORKAaY6Tm\nV7N0Ygj1zUZ+/2F6n+d3LF9dLKRBtCAMPiLug0BhVT23PL+XLzNLHTruX5+fwtPVhTtbmzkDJEX5\nUVLT2GVbuq7IKq2jtrGFtbOiuGv5BN79Op/dpzvP58S5am54Zg+ftqbvd0dKXpU0iBaEIYKI+yDw\n+YkSvjpVxq0v7OP5XVnYKseTVlDNn7eeYNORfBpbjJwtreP9I/l864Jx7cRzamskSVpBdadzmDmU\nXc57X+e122a2smfGBHDvxROJDfLmofdTqTrfbBlTVtvId/53kP1ny7nzpYM89fkpm3O1nDOvylIb\nRhCEwUUWVAeB4wVV+Hq6snhCML/9MJ3U/CqWt4by1Ta28N7X+ZZeogBBPu6E+3ni5mLgu8vGtzvX\nlEi/1nNWc1FiWKfXOllUw63/2U9Di4kViWEEeLsDkJJbhZebCxNCfXB1MfD7a6Zz+//2s+6pL3n+\n2/OIDfLhe68cpqS2kTc2LOLV/Tn8eWsG6YXVPLJ2KiEdrPOKuiZyys9z80JpwiIIQwER90EgrbCa\npEg/nr5lLk98lsnj2zN5/4i1RP6EUB/+b00S35gdTWpBFa/szWFbehF3Lo3v1CLO38uNsUFenRpb\ngBLcO188CIDRpLMjo8RSWOtYfhXTov0sPUaXJoTw6ncX8b2Nh7j6qd3Miwtk/5lyHv/mLBaOD2ZB\nfBBJkX489vEJth4/x6ppkdyyMJaF8UFomsaxfOX3F3+7IAwNRNwHGKNJ50RhDTctiMVg0PjRpZO4\nZeE4zjepmHWDphET6GVJ6FmWEMqyhFBqG1vwcnOxec6kSL9Obplmo4nvv3KYc9UNvPbdRdy98RDb\n0oq4enY0LUYTxwuquHlB+/DH+XFBJN+7lA0vH2RHRgl3XzjBcjHQNI27LpzAJVPCeGVfDu8cymNz\nSgFrZkTyp+tmWDJTpUG0IAwNRNwHmDOlddQ3G9tlXSprvPtFyO4yLJMi/fkkrYjaxhbLuMe3n2RP\nVhl/vX4mc8cFcumUMJKPFNDYYiSrpI6GZpNN/3hUgBdv372YvVllLEvonPU5McyXX101lZ9dPpn/\nfJnFX7edJKukDm93F8aH+EgfUUEYIsiCaj+SV3GeJz/LbJcBerxAuS+mdpNS7yhTo/zQdcg4p6z3\nZqOJ1/bnsmpqBNfOjQFgZVI4dU1G9pwus1jZ07twoXi6uXBRYhgu3WR9erm7cO/FCbzw7fnkVpzn\nYHaFw5mpgiD0HyLuvaS4uoFTxTXdjnl+1xn+8snJdu3i0gqrcXcxMCHUeeVnzXcBx1tdM1+eKqW8\nrski7ACLJ4Tg7e7C9vQijuapBd24YJ8+v/aKyWG8f88Slk4M6dQoQxCEwUPEvZc89vEJvvvSoS73\n67rOtjQVG27+CSpkMSF8DO6uzvvTR/p7EujtZvG7Jx8pwN/LrV0xLU83F5YnhLI9rdhS/8VZ9Vgm\nhI5h450LbUbrCIIwOIi495K88nryK+u7jPtOL6whv7IedxeDRdx1XSetoNqpLhlQi51JUX4cL6im\nvsnI1uPnuGJ6RKcLyMqkcM5VN5CaX8306J5L8gqCMHwRce8lRTUNNLWYqK63XZlxe3oRmgZ3Xzie\nrNI6TpfUUlTdSFldE0mRzhV3gKlR/mQU1fDx8ULONxlZO7Ozi2TF5DDMxvpM8Y8LwohGxL0X6LrO\nuSqV7l9Sazvtf1taEbPGBnDjgljL87TC1sXUfogFT4r0o6nFxBOfniLCz5OF8UGdxgT5uFsaYEhx\nL0EY2Yi494Lq+hYaW0wAFNd0rqZYWFXPsfwqViaFExXgxbRoP7alFXE8X/nEJ0fYbhnXF8yunjOl\ndaydFdWlP/2OJXGsmhpBdC9KBAuCMHyQOPdeUNSmSFeJDXHf3upjvywpHICVUyJ4/NOTGDSIC/bG\ntx9iweNDfPBwNdDYYmLtzKgux62aFsmqaZFOf31BEIYWYrn3ArNLBmyL+ydpRcSH+FjCHS9NCkPX\n4cDZim5bxvUFVxcDU6P8mBg2xukLtoIgDD/Ecu8FRdVdi3tNQzN7s8q4fUm8pYRAUqQf0QFe5FfW\nMzWq/3zdf//mLHSdTr1IBUEYfYjl3gvMfvaQMe6dxP2LkyU0G3UunRJu2aZpGitbXTT9ESljZlyw\nD3EhfU9MEgRh+COWey8oqm7A38uNmEBvSjq0pzuSU4mHq4G54wLbbf/m/LGkFVYzN679dkEQhP5A\nLPdecK6qgXA/D0J9PTpZ7rkV5xkb5N2pLsuUSD/evOsCKazlCM0NUJo52LMYeRhboChtsGch9DMi\n7r2gqKaRcD9Pwnw9OoVC5pbXMzZQwgydws4/wdOLoc6xdoRCD3zyS3hmCdQWD/ZMhH5ExL0XFFc3\nEO7nSaivB+V1TTQbTZZ9Zstd6CO6DqnvgrEJTnw42LMZOeTsg33/Bt0EFdmDPRuhHxFxdxCjSae4\nptHilgEoq20CoOp8MzUNLYwNFHHvM0WpUHFG/Z6ePLhzGSm0NELyfeDW+vmsKeh+vDCsEXF3kLK6\nRowmnQg/T0Jb+4ia/e65FecBGBskbpk+k5YMmgFm3gxZX0B9Zc/HCN2z8y9QmgFr/q6eV4u4j2RE\n3B2kuFoJeVirWwas9WVyypW4x4jl3nfSkyF2Mcz/Dpia4eTHgz2j4U3RcfjybzDzJphxA7h42C/u\nJiPse1Z89MMMEXcHMScwhft5EubnCVgFP7dV3GODRdz7RMlJKDkBSWshag74RStLXug9qe+odYzL\nfw+aBn6R9ov7/mfho5/Cnqf6d46CUxFxd5BzreIe4edJyBh3oL1bxt/LTcId+4rZxz7lKjAY1M/T\nn0Jj7eDOazhTcRb8Y8C7tVqoX7R94l5xFj59VP2enqwuEMKwQMTdQYqqG9E0lZ3q4eqCv5ebJZEp\nt7xe/O3OID0ZYuaDX2sBtClXQUsDnNo2uPMazlRkQ+A463PfyJ4XVHUdNv9QrX0sux/Ks5R7RxgW\n2CXumqat0jQtQ9O0U5qmPdDFmBs0TUvTNO24pmmvOneaQ4fi6gZCxnjg6qL+dG0TmXIrzkukTF+p\nOAuFKTBlrXVb7AXgEyqumb5QmQ0BbcTdLwqqC7u3xI+8Clk7YOWvYeFdgCaRS8OIHsVd0zQX4Clg\nNZAE3KRpWlKHMQnAg8ASXdenAj/qh7kOCc5Vq+xUM+ZEJpNJJ6+8fnBj3L/6Bzx7kfVhvp3uD1oa\n4c1vQ/Zu5543/QP1M6mNuBtcYPKVkPmJyloVHKOpDupKIDDOus0vGoyNcL7c9jHny2Hrg2pRe+4d\nMCYMxi3u3QV279Ow44+dtx9/Dz68H0ym9tvPfgVv3Q7GZsdfS7Bgj+W+ADil63qWrutNwOvAug5j\nvgs8pet6BYCu6yN2Wb2oupGI1oVUsFruxTWNNBlNg5edemYXbHtYJaf4hILBFXb9FdI29c/rZe2A\ntPfh3buc6wsvTgPfqPZCBDD+ImiqhdKTznut0UJljvrZTtxba/pX59s+Jj0ZGqrg8t+pdQ9Qd1Ml\n6Y6VhDA2w47HYMfv4fTn1u0V2fD+9+HAc3DoBev2xhp4dwMcfxfOHbP/dYRO2CPu0UBum+d5rdva\nMgmYpGnaV5qm7dU0bZWzJjjUKK5usETJAISOUeJujXEfBMu9uR42/wAC4+H2j+GWt9TPyJnKMqqv\ncP5rpiWDqydU5cJnv3HeeasLrL72toROVj9LMpz3WqOFirPqZzu3TOtXuKtF1bRkdTGImm3dNmWN\n+umIa+bsLmioVIlTm3+g7iLa+vJjFsC2X0Flq8Rs/zVU56nf8w/Z/zpCJ+wRd1vFwTs66lyBBOAi\n4CbgeU3TAjqdSNM2aJp2UNO0gyUlJY7OddBpbDFSVtdEuG97y72+2ciJQtVCb1DEfccf1GLX2ifA\nvfX1XVxh7ZNwvgy2PuTc1zM2Q8aHypKbf6dKZ8/d75xzdyXuQRNAc1FJOIJjmMsMBHbwuYPtRdX6\nCjjzhfr/tu0N4B8D0XMdc82kJYObD9z4irqD+Oy3rb78z+HSR+Da59Td5gc/Vi6+A8/BwrvBJwzy\nDjr6ToU22CPuecDYNs9jgI6fiDxgk67rzbqunwEyUGLfDl3Xn9V1fZ6u6/NCQ0N7O+dBw7xwGuFv\n9bmbE5kO56gMyn7rTWoyKqun4yN3P+z+J8z5NsQvb39M5AxY8kM4srH9LXFfOfulEoCktXDpr5QV\nuOle5YfvK9UFVquyLa7uEDRexb/3ldEWzleZrSxnnzbfOZ8wZTnbstwzPgZTCyR19L6iBL/wiMpF\naKqDpvNdv67JCCc+gISVMOFiZQjsfRo++rlaJJ/3HXV3cMnDKhLqtRvBPxYu/j8VLZUv4t4X7BH3\nA0CCpmnxmqa5AzcCHS/d7wMrADRNC0G5abKcOdGhQFGb7FQzYa1W/KHsCsL9PPB0c3HspJW58Ng4\nVdCpK86Xwz/nwu+jOj/+sxLGhMPKLhZPL/w5BE9Ut8TO8o2nJyuxmHAJePjCVY8ri/rQi307b0M1\nNNVY/cEdCU1UotIXdB2enA+fOtGVNNSpyIaA2PZWuIsrjIlQETMdSU9W6x5RczrvMy90PzW/9TMY\nCZ/9zvbr5uxVC7nmYy5pNQSMTbD2n1Zf/oINSswbqtRnyWMMxMyFslNdL/gKPdJjsw5d11s0TbsX\n2Aq4AC/oun5c07RHgYO6rie37rtM07Q0wAj8VNf1sv6c+GBQbM5O7eCWAVV6YN64XjTiyDugfJJH\nXoHYhbbHbP2F8m2veEhZsB2ZtBq8OnnBFG6eyj3z31Xw+e9g1R8cn2NbTEYV0ZKw0uoCSlgJXoF9\nt6prWoXGluUOEDJJlSEwNoNLLxPFagqhLFOl4ideoURkpFOZ3XmBGlrDITssqDbWwqlPYe5tVvFt\nS9B4uO6/6vMIkL0Hdv4ZEi6DsfPbj03frMocJFymnnv6wbeTVQnnkDY39gYXuPFVKDwKEy9R26Ln\nqZ/5hyHhUkffsYCdnZh0Xd8CbOmw7eE2v+vAT1ofI5ZzltIDnd0yALG98beboz9OfKgKOhk6WP6Z\n2yHlNVj+U7jwp46fH2DcBdZb4qnf6PwldITc/VBX3D4OHZQg19iwAh3BLDS+XVnuk5W7oDxLWfG9\nwbwgq7lA8r2w4QvbF8yRgq4ry33cks77/CI73wllfqJCJJPWdh5vZto3rL/PvR3+tUj9Le/aCa4e\n1tdN36zE2sPXOj54gnp0ZExYexGPngNoyjUj4t4rJEPVAYqqG3Fz0QjysYpBgJcbrq1dl2J6I+5m\na/d8aeeY8cYa+OBHymJd3kthN2O+JU7uo288PRlc3GHS5e23+0Z2HVZnL2YXga0FVYDQSepnXyJm\nzMde+RcVdvnV470/13CgvkK5utouppqxdUFOT1a++dgL7Du/p58ySkpOwK6/WbfnH1ZRLx2NAHvx\n8IWwKbKo2gekh6oDFFc3EObridbGd2kwaIT6elBY1dC7GPeSkxC3TLln0pMhfpl136e/gao8uGOr\n1SLqLeYv4avXqy/higcdP4fZGptwcXtrDJQgFx7p2xzNi3tdWe4hThD30gzw9FcL0Gd2wRd/UgIU\nNrn9uJpzKoqjqwtNR5rr1UKzyWj/XFzc1CJ4b11M9mArDNKMbyQ0VisjwsNXvYeTn8CM6zvfQXbH\npMth+g0qryJovPr7pr6jci0S+xAVHT1XLcjqevv1AkcozVQXMfcOhldlLrj7WGvtjEBE3O0ku6yO\nT08UM3NsZ9+2RdwdtdyNLWrRaOJd6guRvhlW/VH5OnP2qmp8CzZ07Yt3lEmXwbRr4cu/w9IfK3+8\nI5RkKF/rhT/rvM8vWi2etTT13s1RnQ/ewV3Py91HRVP0JRyy5CSEJCqxWP1HOP2Zupu5Y6tV0Bpr\n1UK1ZwDcvcu+8+5+Ej7/rePzWfN3mHeH48fZi1ncu7LcQd0xhfqqv0VzXe+s7VWPqcS29zZYt01a\npdZiekvMPPj6ZeWGs+XK6YmWJvj3hTDvdpWMZcZkgv9eAdGz4YaXej+/IY6Iux3UNDRz54vq9vA3\n66Z22m9u2uGwuFdmK/9maCKET1NWSv5BiJihOub4j1VhYs5k6jXKqjp3FMYucOzYknT1M3Jm533m\nCJeaQttCYg81hT1byqGT+rZwW3ICEler331ClMC/+111IV30PbX9s9+2ZnXmQNlp+4Tl+HtqEfCK\nP9s/l3e/C8ff719xr2yNcbdluZv/1tX56u+alqwuaB1Dau3BJxju3Q/lZ6zbQjpFQztGTOvaUN7B\n3ol7+Wl1sTr+Hqz8jXWBOP8QVOWoYnR9uSsY4oi494DJpPPjN46QVVrHS3csYFywT6cxob4euLlo\n7coS2IXZvRA6WYUrGtxUuYCTW9VC6/p3VFiYMzFHIeQd7IW4ZwAaBNv40lqEoqD34l6dr0LwuiN0\nstX94YjrAKCuTK1ttF2MnX49HHtL1eFJXK0aUux7BiavURfb9GR1l9MdZaeh+LiyXqNthA92RdI6\n+PJxFe7XX+6BimzwClJuuY5YShAUKCs34yNVw6e3biKvQIjug6XekdDJ4D5GGTwzv+n48WYjoDof\nCg6rOwGA9NaSHHXF6k40INY58x1iyIJqDzzxWSbb04t5eE0SSyaG2Bxz25I4/njtDFwMDloA5g9f\nSIIKZRx/EaS8rhb5Zt4ME/shSsAvUt2O9yZBpCRDfRE6+i/Beovfl76cXWWntiVkkrK4zPVSHKG0\nzcXUjKYp14hmgOQfqDsmv2i45hmVem9PNqa5fs/kNY7NZ8pVoBv7twF4ZXbXF1vzhbSmAM7shMYq\nNaehgsFF/Q/yDvTu+JKTgKZ8/+b/ka6r/6lfjHo+ghdsRdy7Qdd1XtmXwyWTw7j1gq6t0ckRfnxj\nTozjL1B6Un3BPP3V86S1yrL0CmzvI3Q20XN796EuyWgvjG3xbWMF9obmBlUqoasYdzPm17dVQMzY\nonzfXSW+mO+UzAuzZvxjVFnbM1+oC+5Vj6sFxilrlcVnrnvSFenJKuEnYGz34zoSOUtdLNM3dz0m\n9R0oTnfsvG2pyLbtkgG1tuEdrP5n6ZuUlTzh4t6/Vn8QMw/OpfauGmhpqzESf6G10ci5Y+qCt+zH\nqjaSiPvoJK+inpKaRi5MDG0XIeM0SjKs4X2gLL+QRLjqif5dxY+Zrz7gtQ7U9zEv/oZOsr3f01/V\nEOmtuFsSmLqIlDFjCYe04Xc/uxM++SVsud/2saUnVWatvw0RnnsHJF0Ni+5RSVlgXVg88UHX86nM\ngYKvu48L7wpNU6+R9bnKzu3I6c/h7TvglRt6l11sMim3Q3duMt8odfE68aFKNnJ0kb2/iZqteuiW\n9OICV5KhXHBJa9XC8rljSuQ1g/pfR84a0SUORNy74XCOqqY4J9aJfkQzuq7EJqSN/9c7SC1KTb7C\n+a/XFrPv0ZEPtmXxtwvLXdNaMx57Ke7m43pyy3gFqnILtsoQ5LVWEUx9R/mPO1JyQrnAbGVeGgxw\nw4uw6vfWbSETISype9eM2erubTz3lLUqHf/k1vbbm+pU5UTfyN5X3qwpVOfuynIH9fc+84W6a+rN\nBaq/sVQDdbDshMmowiBDE5XRpBmUsKclq4QunxD1PShMGbF140Xcu+HrnEq83V2YHOHb82BHqc5X\n9cl7m2nZFyJnqQxNR25JLS6NbubrSNPljpgt954WVEG5VWxZ7nkHVPXIsKnwwU9UrZK2lJzs+uLU\nFVPWQs4eqCmyvT8tWUU69SaaA9RdlG+kdZHPzGe/UxfUa//T+8qb5kiZ7ix3v0h1AXD1hIkrHTv/\nQBA0XvnMHY2QqjirjJGQRCXk45bAwReUq8ZcEC16rlq/KUp1+rSHAiLu3XAou4IZMf6WlnpOxfxh\nHQxxd/eG8CTHLHfLfLtwy0DfShCYs1vtSRoKTVR3PW2rO+q6ej+xi2DdP6H2nKoTbqaxRmVMdvS3\n90TSWkC37ZqpOQe5+3pvtYO6Y5i8RpWZaKpT2/IOwt5/qaqJcUt6X3nTEuMe3/UY8xrHxEudH5nl\nDFzc1AXb0SYt5vHmi/mUteruBKwL3zFtIsdGICLuXVDfZCS9sNpxl8zpz1SLu38v7/zYeJ0KtQPr\nbaajlqSziJ6nUsQ7tjjritKTysI0L/7awi9KibsjWZpmqgvA3dd2yF5HQierzMq2dwkVZ9WXN3qu\nelxwDxz6r8pCNc/ffKwjhCUpcUl9p3Op4NR3Ab3v7oyktdBSb/3cvHqD+lte+oja37by5u4n7D9v\nRTagqQXjrrA0IR+CLhkzoYmOW+4djRFzo5GxC63rOv5jB75ufNN5VZU09d1+fykR9y44mldJi0ln\nrqOVHvf8SyVy+EZ2fpz5Aj5qze4sOaHij31sh1f2OzHzlUDaaxGVnOjZ6vWNVIW96nrRiKW6oOfF\nVDPm5JbTn1q3mbv2mK2xi36hLNbNP1BfKEtOgYN3SpoG878D2V+pZBgzNUXwxR9Vj9G+XqDHLVEF\nuILGq79h7AVw/YvtL3QJK9X2E1u6Pk9Hyk4pAeuudMXElTD/u1bxG4qEJqrvlCN3LSUdjBG/KFVf\nacUvrGM0beDrxhemqO+ca/8vXEsSUxccal1Mne2I5V5fqVKwF95lO5Txiz+rFPXp16t/8GBZ7dB+\nUbVjXZWO6Lr6ssxe3/24tq3bfCMcm489Me5mImdaQwjn3Kq25R0AVy/lbwflelr7BLx4lepUpRlU\nklh3LoquWHCXSnTa8lOVi+AdBB/9VNViWftE3zMcDS7KMu+JsQthz1MqLNCeqBZztEh3+IarImpD\nmZBElQ9Qdlq5E+2hNKOzMbLMRtHamLmqq1h/JpK1xXwhMX//+hGx3LvgcHYl8SE+7SpA9sjJrSps\ny1YHG4ClP1KLbx/8RFUk7M5/3d8EJ4CHv323pFV5Ko27p/m2zVJ1lJpC+xZTwRpCePpz66Jp3kEV\nNufSxl6JX64KhO15UoX6BU9sv99ezC0LGypVbf30zSop5qKf9z3F3hFi5qnP17mjPY81GVXd+sFY\n03E25vdgb00hszFiz3tvWzd+IMg7qAyTMWH9/lIi7q288OUZ9mapBRdd1/k6p8Jxf3t6sroVjO7i\nquziBuueVGnPDVWDa7kbDKpwUt4BFWPd8dH2FthWZqcteivuxha1OGmv5Q5K3E3N6oLa0qgEz1bj\njZWPqtDJvgpdxDRY+hNVW//9eyBiOiz+Qe/P1xuiHVgArMxWkSAjQdxDEgCtczXQ5gbr57Vtu7/q\nAlXm2J73HjVbnTtnt/Vc9qwZNdW1+a402R5jaz0r/1DX+uBkxC0D5JSd59EP0vB2d+Hd7y/G09WF\nsrom5ozroruRLZrqVAebOd+yHUdtJmo2LL4PvvrH4Io7qM7zO/8Ej9lI6nH3hW+9q+rP2BMGCeAd\nolwfjpYgqCtWt92OiLs5hDBtk1rwNDbZ/tJ4BcCVf4PXb1L1wfvC8vvV65WdUpZ8f5bqtYVfpEqb\nt8dHPNgL9s7EzUuFc7YV95IMeGap+r+DCpe8+mmYcUObsh52iLunn1o03/VX9QCV0frtbnIb9jwF\nW38JtC6wewWpqqJt72yzvoDXboLbP2y9gKAMmKpca4G6fkbEHUhOUWF43u4u3PniQW5bHAc4mLyU\nuU1FPNgTdbDil6ryY2+q7zmThXer9HNTS+d9+55RoXd371JfJHsWfw2G3sW699Sko6vXmrwGvt6o\nomPAutDakclXwE2vq4tZX3D1UBe8imyImtW3c/WWmLn21VqxCNwguv6cSUhie3E/9pb63K58VOVs\npL6jMpPjlzseGbXuSWujnLz96gJelWc7yqgkA7Y/AuMvbM0L0NVFIfk+uP0j9blsqlPPm+vg6JtW\ncTffcYnlPjDous77RwpYEBfEL66cwg3/3sPvt6QzxsOVSeEOJC+lJyvLddzinse6esD063o/aWfh\nEwyL7ra9L3QyvHIt7PxL6+Jvon0Lh769yFJ1JMa9LUlr4cBzyqfuGwn+3dSlMZf57Sv+Md2HFvY3\n0fOU+NSWwJjQrseVnlTuqK566w43QhNVsIK5Gqg503TJD9X+Savg6cVK4L2DVSazvZFo0XOs1TxL\nT6m/b/rmzha2yagMHncf+Mbz1r+/dwi8fzcc/A8s+K41AS14ojrP5b9X3538g+rONnKGU/4kPTHq\nfe5phdWcKq5l7awoZo0N4I/XTsekw6yxAfZXeWxuUL7fyVc6XoZ2qJJwKcy8STWSLkyx33fbmxIE\nlg5MDop77GL1RTbHt48G7C0dYU+kzHAiNFFlnFacVe+tNKP9XXLIRNVdLH0zpL6njJPeRDF1V3Li\nwPPKsl/1x/YX1pk3woRLlEWf+q5KQJt/p1qjqcpVtYdAWe4R05SbaQAY9eKefKQAV4PGFdNVjPU1\ns2P46/Uz+cllrbezVfnWxKOuyPpclRIYirU5+sLlv1fNG5rP2+e/BKu4mxN+KnM7lwEAVVv9xIfq\nkbNb9WX1DnZsfi6u6oIKAxJaNiSwp3SErisBtPd/Nhyw1JjJUHfJ0Dk2/4L7lLuzsapv7ihbJScq\nsmH7r5UrZsYN7cdrmgpl1XV4+3ZrTH3iarUWkJ6srP6CrwfMJQOjXNxNJp3klAKWTwptF/J47dwY\nq7/9rdvgzW93f6KTW8HDD+IG2YfubLyDrDHQ9jah8ItSaw8NlcqX/vQS+O+V7YszNdfDfy6F129W\nj7RNrc1KevFxnN76RRtpf/uucPeG8Knd+91rCu2PFhkumENOSzOUVR2zoLMbz8VV+c9d3B1rmtKR\njiUndF01qtc0WPM323cEAbGqbLRmgDWPq4Va7yDVHzktWa2BNNUOqBEyqn3uB86WU1jVwAOru1l4\nKc4OIQIAAA0kSURBVM1Qlmd1YdcZlHkH1T+tt71DhzJTr1HuD99w+8abv3BV+fD579WiUtExFR20\nvLUU744/qL6Y33jeGmFgqwyvPcQvg/szByRueMgQMw+Ova1C7WxdEAezblF/4emv1lVOfqLCXi/r\nol9t5Ez4cVrfEpLMJSfSk1V2csprqqzIFX/pvmvTgu+qHsVtX3vKVfDhT+Dwy+p5V4v+/cCottw3\npRTg5ebCpVO6EK76SqtLoaua3k11qsXaAN5uDTj2CjtYs1T3Pq0y/y55WCV1ffEnFZ6Xfxh2/1Nl\nls64Xn0ZI2f27cs4moQdei4dMZLCINsSmqhceNB9x6gxoX1b+9I0Zb2f2QXFJ+DjB2HsIlXIrSc6\nfo4nrwE05a/3ClQlJgaIUSvuRpPOlmOFrEwKx8ejixsYc8lUsPr5OlLwNeim0ePz7QlzR6YjG5V/\neNE9sPrPahEp+T7Vys4nTDUsFnqHJZmpC9dMyQm1VuLTTTTNcMS8hhA5EwLj+ve1pqxVuRcvrVVu\nxHVP9s5t6BuuagKZmtWi/wA24x614n66pJbK881cOKmbL4C5ZGrCZXD2K7UI2JEBjl0d8vhGYOlb\nue5J5Qf1DYdVf4DcvcpFc+VfR06I3mAQPLG1dEQX4m6uWzSAQjIgmN1MA1HBMmo2+MdCbRFc+LO+\nlZkwB1oMsEaMWnFPya0EYObYbkrYVrRa7ot/oK7iGTYaGecfVMWofByM9BipuLipi+ElD6sUfTMz\nb1KPBRuGdgXC4YDBABNWKL+7rUbhJScGt25RfxF/IYRO6Ryt0h9oGizcoHrKmmPpe8vUa5Qfv787\nrHVg1C6oHsuvwsfdhfiQbhoUVGarhZy4papVWVqytQqhmbyDar9g5ZY3O2/TNLjmmYGfy0jlst+o\nrOjNP4L171it9LpSFfc/0vztoGLQ79k7cK+3+D716Cu+EfD9PX0/j4OMXss9r4pp0f7dJyqZO8eb\nF1iydqhFVjNV+SrsTFwywkATEKuaeZz+FFJet263tw6QMOIZleLe1GIivbCamWN78PtWZlv7T05Z\nZ61CaMZSm3ngwpsEwcL8O1UUx8cPWBPtLBU8RdxHO6NS3E8W1dDUYmJ6dDf+dl1X/kxz5/jouSo9\nPvVt65i8gyphImJa/05YEGxhMMDaf6oM4n9fCE8vhc//AG4+g1v/RhgSjEpxP5qnYtdnxnRjudcW\nqXrY5pArgwHm3QGZn1it97yDKt25uzZmgtCfhE6CbzynojsCYtVd5EUPjLxIGcFhRuWC6tG8SgK8\n3Rgb1E0BH0vn+DjrtiU/hOPvwgc/hru/hMIjnRdYBWGgmXq1eghCG0at5T492h+tO+vGHAZpdsuA\nKi+w9km1iPrGt9TtsPjbBUEYgow6cW9oNpJRVMOMmG787WDNTu1YSyJmLiz8HmR/qZ6PllKzgiAM\nK0aduKcVVmM06czozt8OynIfE2G7y/zFv1QWvU9o/6dBC4Ig9IJR53M/2pqZapflHjjO9j53H/jW\neypZRBauBEEYgthluWuatkrTtAxN005pmvaAjf23aZpWomnakdbHnc6fqnM4ml9FqK8HEX42LPK2\nmBOYuiJ4gmoeLQiCMATp0XLXNM0FeApYCeQBBzRNS9Z1Pa3D0Dd0Xb+3H+boVI7mVTEzpofFVGMz\nVOd1bbkLgiAMceyx3BcAp3Rdz9J1vQl4HVjXv9PqH/afKed0SS3To3vwt1flqjK+4k8XBGGYYo+4\nRwO5bZ7ntW7ryLWaph3VNO1tTdNsttXRNG2DpmkHNU07WFJS0ovp9p6Ne7O5+bm9xAf7cMP8HrL3\nbIVBCoIgDCPsEXdb/gu9w/PNQJyu6zOA7cCLtk6k6/qzuq7P03V9XmjowDQSMJp0fvneMR56P5Wl\nCSG8d88SIv176D5uDoMUt4wgCMMUe8Q9D2hriccABW0H6Lpeput6Y+vT54AhE/z96r5sXtmXw4bl\n4/nPt+fj7+XW80EV2arZhJ+tGxRBEIShjz3ifgBI0DQtXtM0d+BGoF3POU3T2naOXgukO2+Kvae4\npoE/bc1gycRgHlw9ufvyvm2pzFaFl/rSh1EQBGEQ6TFaRtf1Fk3T7gW2Ai7AC7quH9c07VHgoK7r\nycAPNE1bC7QA5cBt/Thnu/ndh+k0Npt4dN207qNjAA79D4paA4Cy9/StrZYgCMIgY1cSk67rW4At\nHbY93Ob3B4EHnTu1vvHVqVI2HSngB5ckMCG0m25LADVFqqONm5cq4QuqVZwgCMIwZdhlqKbkVrL/\nTHmP417Zl824YG++f9GEnk964gNAhzu3Q/jUvk9SEARhkBl24r43q4w/fHSix3Febi48d+s8PN3s\n8JunJ0PQBNXEVhAEYQQw7MT99iXx3LKo5xBFV4Nmn7CfL4czu2DJD6ROjCAII4ZhJ+7urgbcXZ1Y\nzDJjC+hGmLLWeecUBEEYZEZdyd9OpCWDf6xqUyYIgjBCGN3i3lANWZ/DlKvEJSMIwohidIv7ya1g\nbIIkcckIgjCyGN3inr4JxoRDjNRlFwRhZDF6xb0qHzK3w+Q1YBi9fwZBEEYmo1PVdB0+/H/q98VD\nvr+IIAiCw4xOcT/+Lpz8CC5+CILGD/ZsBEEQnM7oE/fz5bDlZxA1BxZ9b7BnIwiC0C8MuySmPvPx\ng9BQCeuSpaSvIAgjltFluWdug6Ovw9KfSIEwQRBGNKNH3BtrVFnf0Mmw/P7Bno0gCEK/MnrcMtt/\nDdX58J1PwNVjsGcjCILQr4wOyz17Dxx4HhbeDWMlYUkQhJHPyBf35gZIvg8CxqrQR0EQhFHAyHfL\n7PwTlGXC+nfBo4d2e4IgCCOEkW25Fx6FLx+HWbfAxEsGezaCIAgDxsgVd2MLJN8L3sFw2W8HezaC\nIAgDysh1y+x5EgpT4IaXwDtosGcjCIIwoAw/cT/8shLunig7rZpwJK3r/zkJgiAMMYafuHsHQWhi\nz+PGLoCL/6//5yMIgjAEGX7iPvlK9RAEQRC6ZOQuqAqCIIxiRNwFQRBGICLugiAIIxARd0EQhBGI\niLsgCMIIRMRdEARhBCLiLgiCMAIRcRcEQRiBaLquD84La1oJkN3Lw0OAUidOZ7gwGt/3aHzPMDrf\n92h8z+D4+x6n63poT4MGTdz7gqZpB3VdnzfY8xhoRuP7Ho3vGUbn+x6N7xn6732LW0YQBGEEIuIu\n/P/2zia0jjIKw89LYqutSFpB0aTQFoJaBG0RiT+IVBdtFevChSLYRcGNYBVBKq5cCuIflIK0ahWp\nYiwauhAkFlwZtSo12mrjD200moK2ipu2+Lr4vsAl5AZJ7zjMd88Dw8w5d2DO4Z373pkzExIEQYE0\n1dxfqruAmujGvruxZ+jOvruxZ6io70bO3IMgCIL5aeqVexAEQTAPjTN3SRskfStpQtL2uuupAkkr\nJB2QdFjS15K25fxySR9IOprXy+qutdNI6pH0haT9OV4laSz3/JakRXXX2Gkk9UkalnQka35Dl2j9\naD6/xyXtlXR+aXpLelnStKTxltyc2irxYva2Q5LWncuxG2XuknqAHcBGYA1wn6Q19VZVCWeBx2xf\nBQwBD+U+twOjtgeB0RyXxjbgcEv8NPBc7vkPYGstVVXLC8D7tq8EriH1X7TWkvqBh4HrbF8N9AD3\nUp7erwIbZuXaabsRGMzLg8DOczlwo8wduB6YsP2D7dPAm0Bx/yTV9pTtz/P2X6Qvez+p1z15tz3A\n3fVUWA2SBoA7gF05FrAeGM67lNjzRcAtwG4A26dtn6RwrTO9wAWSeoElwBSF6W37I+D3Wel22m4G\nXnPiY6BP0mULPXbTzL0fON4ST+ZcsUhaCawFxoBLbU9B+gEALqmvskp4Hngc+CfHFwMnbZ/NcYl6\nrwZOAK/kcdQuSUspXGvbPwPPAMdIpn4KOEj5ekN7bTvqb00zd82RK/Z1H0kXAu8Aj9j+s+56qkTS\nncC07YOt6Tl2LU3vXmAdsNP2WuBvChvBzEWeM28GVgGXA0tJY4nZlKb3fHT0fG+auU8CK1riAeCX\nmmqpFEnnkYz9Ddv7cvq3mdu0vJ6uq74KuAm4S9JPpHHbetKVfF++bYcy9Z4EJm2P5XiYZPYlaw1w\nO/Cj7RO2zwD7gBspX29or21H/a1p5v4pMJifqC8iPYAZqbmmjpNnzbuBw7afbfloBNiSt7cA7/3f\ntVWF7SdsD9heSdL1Q9v3AweAe/JuRfUMYPtX4LikK3LqNuAbCtY6cwwYkrQkn+8zfRetd6adtiPA\nA/mtmSHg1Mz4ZkHYbtQCbAK+A74Hnqy7nop6vJl0O3YI+DIvm0gz6FHgaF4vr7vWivq/Fdift1cD\nnwATwNvA4rrrq6Dfa4HPst7vAsu6QWvgKeAIMA68DiwuTW9gL+mZwhnSlfnWdtqSxjI7srd9RXqT\naMHHjr9QDYIgKJCmjWWCIAiC/0CYexAEQYGEuQdBEBRImHsQBEGBhLkHQRAUSJh7EARBgYS5B0EQ\nFEiYexAEQYH8C0jMdsW8y2GNAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3f1a07f2e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.871232881938\n",
      "98\n",
      "0.625\n",
      "68\n"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot\n",
    "\n",
    "# plot history\n",
    "pyplot.plot(history.history['acc'], label='train')\n",
    "pyplot.plot(history.history['val_acc'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()\n",
    "print(max(history.history['acc']))\n",
    "print(history.history['acc'].index(max(history.history['acc'])))\n",
    "print(max(history.history['val_acc']))\n",
    "print(history.history['val_acc'].index(max(history.history['val_acc'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a prediction\n",
    "yhat = model.predict(testX)\n",
    "testX = testX.reshape((testX.shape[0], testX.shape[2]))\n",
    "# invert scaling for forecast\n",
    "inv_yhat = concatenate((yhat, testX[:, 1:]), axis=1)\n",
    "inv_yhat = scaler.inverse_transform(inv_yhat)\n",
    "inv_yhat = inv_yhat[:,0]\n",
    "# invert scaling for actual\n",
    "test_y = test_y.reshape((len(testY), 1))\n",
    "inv_y = concatenate((testY, testX[:, 1:]), axis=1)\n",
    "inv_y = scaler.inverse_transform(invY)\n",
    "inv_y = inv_y[:,0]\n",
    "# calculate RMSE\n",
    "rmse = sqrt(mean_squared_error(inv_y, inv_yhat))\n",
    "print('Test RMSE: %.3f' % rmse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
